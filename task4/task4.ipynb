{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Task 4: Game Title Detection\n",
        "\n",
        "Karena Thailand operates five distinct games but can't automatically identify which game is being played from screenshots. The customer support team receives 2,000 daily tickets with images and wastes 10+ minutes per ticket figuring out which game before routing to specialists. The \"Play Multiple Games for Rewards\" campaign can't verify 50,000+ screenshot submissions, forcing manual checks of only 3% (leading to fraud). Players post 100,000+ gameplay images weekly across platforms that can't be auto-tagged for contests or moderation. Marketing can't track which games are trending without manual review. An automated detection system would enable faster support, verified campaigns, scalable content moderation, and cross-game insights."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fy1-5reJdYcg"
      },
      "source": [
        "Since this task used up lots of the resources and wouldn't complete in just one run time so the code you will see onward might be lots of redundant statement just to decrease only my confusion during the working process, but i try to improve the readbility and code format so far. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "you can find all the model loaded through out this notebook in this gg drive:\n",
        "\n",
        "\n",
        "https://drive.google.com/file/d/14cxNf-pA3Xe1jWeFH3qrFUhnYvqJEYbu/view?usp=sharing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NYmZ1HCr83Mi"
      },
      "source": [
        "# Step 1: File Prep"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eslF8Dpp8NXo"
      },
      "outputs": [],
      "source": [
        "# Install Kaggle API client\n",
        "! pip install -q kaggle"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "id": "LHtPOoDM8P_v",
        "outputId": "4e1c3018-ac82-42c9-b132-acf6748ef2aa"
      },
      "outputs": [],
      "source": [
        "from google.colab import files\n",
        "\n",
        "# Upload Kaggle API credentials file (kaggle.json)\n",
        "uploaded = files.upload()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f0-Ckhf48pl9"
      },
      "outputs": [],
      "source": [
        "# Create a .kaggle directory if it doesn't exist\n",
        "!mkdir -p ~/.kaggle\n",
        "\n",
        "# Copy the uploaded kaggle.json to the .kaggle directory\n",
        "! cp kaggle.json ~/.kaggle/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PfiD37B08uAV"
      },
      "outputs": [],
      "source": [
        "# Set appropriate permissions for the kaggle.json file\n",
        "!chmod 600 /root/.kaggle/kaggle.json"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cKjB4wcK8xEh",
        "outputId": "77ee6f4a-eb21-4880-e4aa-af3b06330067"
      },
      "outputs": [],
      "source": [
        "# Download the competition dataset from Kaggle\n",
        "!kaggle competitions download -c cpe342-karena"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "9IzvTg6V8ymv",
        "outputId": "e4a036f6-e7df-4849-8e1a-e2f0d33c1dfb"
      },
      "outputs": [],
      "source": [
        "# Unzip the downloaded dataset into a new directory\n",
        "!unzip cpe342-karena.zip -d /content/cpe342-karena"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "TcuAAQhQ8zXY",
        "outputId": "2ccb7d82-7813-4c0a-9aac-fa0aa32bbd1e"
      },
      "outputs": [],
      "source": [
        "# List the contents of the 'task4' directory to verify the unzipped files\n",
        "# Note: The output indicates 'task4' is not directly under cpe342-karena, but under public_dataset/task4.\n",
        "!ls -R /content/cpe342-karena/public_dataset/task4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TXz7viEivuKa",
        "outputId": "d5a7f90e-0ff3-40ab-e3e9-941f3107be07"
      },
      "outputs": [],
      "source": [
        "! pip install -q tensorflow_hub keras_cv keras-hub"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gZB_dk1P9Arv"
      },
      "source": [
        "# Step 2: EDA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PDdJgwjz9U8l",
        "outputId": "fbd1a06b-c4b1-468f-a902-fd0d34b83472"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Define the base path for the dataset\n",
        "dataset_base_path = '/content/cpe342-karena/public_dataset/task4'\n",
        "\n",
        "# Load the training, testing, and validation dataframes\n",
        "train_df = pd.read_csv(f'{dataset_base_path}/train.csv')\n",
        "test_df = pd.read_csv(f'{dataset_base_path}/test_refined.csv')\n",
        "val_df = pd.read_csv(f'{dataset_base_path}/val.csv')\n",
        "\n",
        "# Print the shapes of the loaded dataframes to confirm successful loading\n",
        "print(\"train_df loaded with shape:\", train_df.shape)\n",
        "print(\"test_df loaded with shape:\", test_df.shape)\n",
        "print(\"val_df loaded with shape:\", val_df.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xzlcsUyw9dSa",
        "outputId": "499ee9f6-9462-490c-d7fd-87097d0a0991"
      },
      "outputs": [],
      "source": [
        "print(\"First 5 rows of train_df:\")\n",
        "print(train_df.head())\n",
        "print(\"\\nColumn information for train_df:\")\n",
        "print(train_df.info())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_M3E9Wzw9gYb",
        "outputId": "49aaeeb7-d5cd-49f0-aa83-0659c786a0f3"
      },
      "outputs": [],
      "source": [
        "print(\"First 5 rows of test_df:\")\n",
        "print(test_df.head())\n",
        "print(\"\\nColumn information for test_df:\")\n",
        "print(test_df.info())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3nmKzTN19iU-",
        "outputId": "dc89e6f3-4a93-4141-a694-9e938fa05cde"
      },
      "outputs": [],
      "source": [
        "print(\"First 5 rows of val_df:\")\n",
        "print(val_df.head())\n",
        "print(\"\\nColumn information for val_df:\")\n",
        "print(val_df.info())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tr4XlLJL9kzv",
        "outputId": "17fbaab7-d9b3-4cae-9e34-0ce4f3d05cc8"
      },
      "outputs": [],
      "source": [
        "print(\"Label counts for train_df:\")\n",
        "print(train_df['label'].value_counts().sort_index())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 671
        },
        "id": "Jrc1hRPt95H0",
        "outputId": "5b9173b3-e1bc-4e74-a8d5-c3ec55899e2b"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Define the base path for the dataset\n",
        "dataset_base_path = '/content/cpe342-karena/public_dataset/task4'\n",
        "\n",
        "# Re-load train_df to ensure it's defined (redundant if previous cell ran, but good for standalone execution)\n",
        "train_df = pd.read_csv(f'{dataset_base_path}/train.csv')\n",
        "\n",
        "# Set the figure size for the plot\n",
        "plt.figure(figsize=(8, 6))\n",
        "\n",
        "# Create a bar plot of label distribution\n",
        "sns.barplot(\n",
        "    x=train_df['label'].value_counts().index,\n",
        "    y=train_df['label'].value_counts().values,\n",
        "    palette='viridis'\n",
        ")\n",
        "\n",
        "# Add title and labels for clarity\n",
        "plt.title('Label Distribution in Training Set')\n",
        "plt.xlabel('Label')\n",
        "plt.ylabel('Count')\n",
        "\n",
        "# Display the plot\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "odDc_X7Qg2Mo",
        "outputId": "3b05d88b-b169-48be-afff-f99f7b8dfc7b"
      },
      "outputs": [],
      "source": [
        "print(train_df['label'].value_counts().values)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 926
        },
        "id": "eFKr3i_p91AT",
        "outputId": "869af114-7917-4ddf-9866-39f28b1ca3d5"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "import random\n",
        "import os\n",
        "\n",
        "# Define the base path for the dataset\n",
        "dataset_base_path = '/content/cpe342-karena/public_dataset/task4'\n",
        "\n",
        "# Get the directory where the training images are stored\n",
        "image_dir = f'{dataset_base_path}/train'\n",
        "\n",
        "# Select a few random images from the training DataFrame\n",
        "sample_images = train_df.sample(n=25, random_state=42) # Using random_state for reproducibility\n",
        "\n",
        "# Set up a figure to display the images\n",
        "plt.figure(figsize=(15, 10))\n",
        "\n",
        "# Iterate through the sample images and display them\n",
        "for i, row in enumerate(sample_images.iterrows()):\n",
        "    file_name = row[1]['file_name']\n",
        "    label = row[1]['label']\n",
        "    image_path = os.path.join(image_dir, file_name)\n",
        "\n",
        "    # Create a subplot for each image (5 rows, 5 columns)\n",
        "    plt.subplot(5, 5, i + 1)\n",
        "\n",
        "    # Read and display the image\n",
        "    img = mpimg.imread(image_path)\n",
        "    plt.imshow(img)\n",
        "\n",
        "    # Add label as title and turn off axes\n",
        "    plt.title(f\"Label: {label}\")\n",
        "    plt.axis('off')\n",
        "\n",
        "# Adjust layout to prevent titles/labels from overlapping\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# VGG 16"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O-w7eool-SJy"
      },
      "source": [
        "# Step 3: Train Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FEuLOSBI-W-9"
      },
      "source": [
        "## Initial"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        },
        "id": "R3WtCvdB-Hp0",
        "outputId": "67a864fa-da08-41f8-d5b5-f28863018946"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.applications import VGG16\n",
        "from tensorflow.keras import layers, models\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "import numpy as np\n",
        "import cv2\n",
        "import os\n",
        "import albumentations as A\n",
        "\n",
        "# Define the base path for the dataset\n",
        "dataset_base_path = '/content/cpe342-karena/public_dataset/task4'\n",
        "\n",
        "# Define AlbumentationsSequence class for data loading and augmentation\n",
        "class AlbumentationsSequence(tf.keras.utils.Sequence):\n",
        "    def __init__(self, dataframe, image_dir, batch_size, transform, shuffle=True):\n",
        "        self.df = dataframe.reset_index(drop=True)\n",
        "        self.image_dir = image_dir\n",
        "        self.batch_size = batch_size\n",
        "        self.transform = transform\n",
        "        self.shuffle = shuffle\n",
        "        self.indices = np.arange(len(self.df))\n",
        "        self.on_epoch_end()\n",
        "\n",
        "    def __len__(self):\n",
        "        return int(np.ceil(len(self.df) / self.batch_size))\n",
        "\n",
        "    def on_epoch_end(self):\n",
        "        if self.shuffle:\n",
        "            np.random.shuffle(self.indices)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        # Get indices for the current batch\n",
        "        batch_indices = self.indices[idx * self.batch_size:(idx + 1) * self.batch_size]\n",
        "\n",
        "        batch_images = []\n",
        "        batch_labels = []\n",
        "\n",
        "        for i in batch_indices:\n",
        "            row = self.df.iloc[i]\n",
        "            file_name = row[\"file_name\"]\n",
        "            label = int(row[\"label\"])\n",
        "\n",
        "            # Construct image path and load image\n",
        "            img_path = os.path.join(self.image_dir, file_name)\n",
        "            img = cv2.imread(img_path)\n",
        "            img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "            # Apply transformations if provided\n",
        "            if self.transform:\n",
        "                augmented = self.transform(image=img)\n",
        "                img = augmented[\"image\"]\n",
        "\n",
        "            batch_images.append(img)\n",
        "            batch_labels.append(label)\n",
        "\n",
        "        # Convert lists to numpy arrays\n",
        "        batch_x = np.stack(batch_images, axis=0).astype(\"float32\")\n",
        "        batch_y = np.array(batch_labels, dtype=\"int32\")  # For sparse_categorical_crossentropy\n",
        "\n",
        "        return batch_x, batch_y\n",
        "\n",
        "# Define ImageNet mean and standard deviation for normalization\n",
        "imagenet_mean = (0.485, 0.456, 0.406)\n",
        "imagenet_std  = (0.229, 0.224, 0.225)\n",
        "\n",
        "# Define training image transformations with data augmentation\n",
        "train_transform = A.Compose([\n",
        "    A.Resize(224, 224),\n",
        "    A.HorizontalFlip(p=0.5),\n",
        "    A.RandomBrightnessContrast(p=0.5),\n",
        "    A.Affine(\n",
        "    scale=(1-0.1, 1+0.1),\n",
        "    translate_percent=(0.05, 0.05),\n",
        "    rotate=(-15, 15),\n",
        "    p=0.5),\n",
        "    A.GaussNoise(p=0.3),\n",
        "    A.Normalize(mean=imagenet_mean, std=imagenet_std),\n",
        "])\n",
        "\n",
        "# Define validation image transformations (resizing and normalization only)\n",
        "val_transform = A.Compose([\n",
        "    A.Resize(224, 224),\n",
        "    A.Normalize(mean=imagenet_mean, std=imagenet_std),\n",
        "])\n",
        "\n",
        "# 1. Reload the dataframes for consistency\n",
        "try:\n",
        "    train_df = pd.read_csv(f'{dataset_base_path}/train.csv')\n",
        "    test_df = pd.read_csv(f'{dataset_base_path}/test_refined.csv')\n",
        "    val_df = pd.read_csv(f'{dataset_base_path}/val.csv')\n",
        "    print(\"DataFrames reloaded.\")\n",
        "except FileNotFoundError as e:\n",
        "    print(f\"Error reloading dataframes: {e}. Please ensure the dataset is unzipped and available at '{dataset_base_path}/'.\")\n",
        "\n",
        "# Define image directories using absolute paths\n",
        "train_image_dir = f'{dataset_base_path}/train'\n",
        "val_image_dir = f'{dataset_base_path}/val'\n",
        "\n",
        "# Define batch size\n",
        "BATCH_SIZE = 32\n",
        "\n",
        "# 2. Calculate class weights to handle potential class imbalance\n",
        "if 'train_df' in locals() and not train_df.empty:\n",
        "    class_counts = train_df['label'].value_counts().sort_index().values.astype(np.float32)\n",
        "    num_classes = len(class_counts)\n",
        "    total = class_counts.sum()\n",
        "    class_weights_array = total / (num_classes * class_counts)\n",
        "    class_weight = {i: float(w) for i, w in enumerate(class_weights_array)}\n",
        "    print(\"Class weights calculated:\", class_weight)\n",
        "else:\n",
        "    print(\"train_df is not loaded, cannot calculate class weights. Using dummy weights.\")\n",
        "    class_weight = {0: 1.0, 1: 1.0, 2: 1.0, 3: 1.0, 4: 1.0}\n",
        "\n",
        "# Re-instantiate data generators to use the reloaded dataframes and absolute paths\n",
        "if 'train_df' in locals() and 'val_df' in locals() and not train_df.empty and not val_df.empty:\n",
        "    train_gen = AlbumentationsSequence(\n",
        "        train_df, train_image_dir,\n",
        "        batch_size=BATCH_SIZE,\n",
        "        transform=train_transform,\n",
        "        shuffle=True\n",
        "    )\n",
        "    val_gen = AlbumentationsSequence(\n",
        "        val_df, val_image_dir,\n",
        "        batch_size=BATCH_SIZE,\n",
        "        transform=val_transform,\n",
        "        shuffle=False\n",
        "    )\n",
        "    print(\"Data generators re-initialized.\")\n",
        "else:\n",
        "    print(\"Cannot re-initialize data generators due to missing dataframes.\")\n",
        "\n",
        "NUM_CLASSES = 5\n",
        "\n",
        "# 3. Re-initialize the VGG16 base model, excluding the top classification layer\n",
        "base_model = VGG16(\n",
        "    include_top=False,\n",
        "    weights='imagenet',\n",
        "    input_shape=(224, 224, 3)\n",
        ")\n",
        "base_model.trainable = False  # Freeze the base model to train only the new top layers initially\n",
        "print(\"VGG16 base model re-initialized.\")\n",
        "\n",
        "# 4. Create the full model by adding a custom classification head\n",
        "inputs = layers.Input(shape=(224, 224, 3))\n",
        "x = base_model(inputs, training=False) # Pass inputs through the frozen base model\n",
        "x = layers.GlobalAveragePooling2D()(x) # Add a Global Average Pooling layer\n",
        "x = layers.Dropout(0.3)(x)             # Add a Dropout layer for regularization\n",
        "outputs = layers.Dense(NUM_CLASSES, activation='softmax')(x) # Output Dense layer with softmax activation\n",
        "\n",
        "model = models.Model(inputs, outputs)\n",
        "\n",
        "# 5. Compile the model\n",
        "model.compile(\n",
        "    optimizer='adam',\n",
        "    loss='sparse_categorical_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "print(\"Model rebuilt and compiled. Summary:\")\n",
        "model.summary()\n",
        "\n",
        "# 6. Instantiate ModelCheckpoint to save the best model based on validation loss\n",
        "checkpoint_callback = ModelCheckpoint(\n",
        "    filepath='vgg16_initial_best.keras',\n",
        "    monitor='val_loss',\n",
        "    mode='min',\n",
        "    save_best_only=True,\n",
        "    save_weights_only=False,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "# 7. Train the model for an initial number of epochs\n",
        "EPOCHS_INITIAL = 15\n",
        "\n",
        "if 'train_gen' in locals() and 'val_gen' in locals():\n",
        "    print(f\"Training the initial model for {EPOCHS_INITIAL} epochs...\")\n",
        "    history = model.fit(\n",
        "        train_gen,\n",
        "        validation_data=val_gen,\n",
        "        epochs=EPOCHS_INITIAL,\n",
        "        class_weight=class_weight,\n",
        "        callbacks=[checkpoint_callback]\n",
        "    )\n",
        "    print(\"Initial model training complete and best model saved to 'vgg16_initial_best.keras'.\")\n",
        "else:\n",
        "    print(\"Skipping model training due to uninitialized data generators.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UaNLC43T-bEX"
      },
      "source": [
        "## Fine Tune"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Qy02yzt6-J4-"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "\n",
        "# 1. Load the pre-trained model named 'vgg16_initial_best.keras'\n",
        "model = tf.keras.models.load_model('vgg16_initial_best.keras')\n",
        "print(\"Loaded model 'vgg16_initial_best.keras'.\")\n",
        "\n",
        "# Find the VGG16 base model layer within the loaded model\n",
        "vgg16_base_model = None\n",
        "for layer in model.layers:\n",
        "    if 'vgg16' in layer.name.lower(): # Check if the layer name contains 'vgg16'\n",
        "        vgg16_base_model = layer\n",
        "        break\n",
        "\n",
        "if vgg16_base_model is None:\n",
        "    raise ValueError(\"VGG16 base model not found as a layer in the loaded model.\")\n",
        "\n",
        "print(f\"Identified VGG16 base model layer: {vgg16_base_model.name}\")\n",
        "\n",
        "# 2. Set the base model's `trainable` attribute to `True` to allow unfreezing of its sub-layers\n",
        "vgg16_base_model.trainable = True\n",
        "\n",
        "# 3. Iterate through the layers of the VGG16 base model and selectively unfreeze\n",
        "#    Unfreezing blocks 3, 4, and 5 for fine-tuning\n",
        "for layer in vgg16_base_model.layers:\n",
        "    if any(block_name in layer.name for block_name in ['block3', 'block4', 'block5']):\n",
        "        layer.trainable = True\n",
        "    else:\n",
        "        layer.trainable = False\n",
        "\n",
        "print(\"Selective unfreezing applied to VGG16 convolutional blocks 3, 4, and 5.\")\n",
        "\n",
        "# 4. Recompile the entire model with a lower learning rate for fine-tuning\n",
        "model.compile(\n",
        "    optimizer=tf.keras.optimizers.Adam(learning_rate=1e-5), # Use a smaller LR for fine-tuning\n",
        "    loss=\"sparse_categorical_crossentropy\",\n",
        "    metrics=[\"accuracy\"]\n",
        ")\n",
        "\n",
        "print(\"Model recompiled with Adam optimizer (LR=1e-5).\")\n",
        "model.summary()\n",
        "\n",
        "# 5. Create a ModelCheckpoint callback for saving the best fine-tuned model\n",
        "fine_tune_checkpoint_callback = ModelCheckpoint(\n",
        "    filepath='vgg16_fine_tuned_best.keras',\n",
        "    monitor='val_loss',\n",
        "    mode='min',\n",
        "    save_best_only=True,\n",
        "    save_weights_only=False,\n",
        "    verbose=1\n",
        ")\n",
        "print(\"ModelCheckpoint for fine-tuning initialized ('vgg16_fine_tuned_best.keras').\")\n",
        "\n",
        "# 6. Continue training the model for additional epochs (fine-tuning phase)\n",
        "EPOCHS_FINE_TUNE = 10\n",
        "\n",
        "# Check if data generators are initialized before starting training\n",
        "if 'train_gen' in locals() and 'val_gen' in locals():\n",
        "    print(f\"Continuing training the fine-tuned model for {EPOCHS_FINE_TUNE} epochs...\")\n",
        "    fine_history = model.fit(\n",
        "        train_gen,\n",
        "        validation_data=val_gen,\n",
        "        epochs=EPOCHS_FINE_TUNE,\n",
        "        class_weight=class_weight,\n",
        "        callbacks=[fine_tune_checkpoint_callback]\n",
        "    )\n",
        "    print(\"Fine-tuned model training complete and best model saved to 'vgg16_fine_tuned_best.keras'.\")\n",
        "else:\n",
        "    print(\"Skipping fine-tuning due to uninitialized data generators.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s1d2Aehl-gpV"
      },
      "source": [
        "## Cross-Validation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mlYQR-L0-e7T",
        "outputId": "b95aba63-3991-48b6-a6d2-f5717f27c1c3"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.applications import VGG16\n",
        "from tensorflow.keras import layers, models\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.metrics import f1_score, classification_report\n",
        "import numpy as np\n",
        "import os\n",
        "import cv2\n",
        "import albumentations as A\n",
        "\n",
        "# Define the base path for the dataset\n",
        "dataset_base_path = '/content/cpe342-karena/public_dataset/task4'\n",
        "\n",
        "# Define AlbumentationsSequence class for data loading and augmentation\n",
        "class AlbumentationsSequence(tf.keras.utils.Sequence):\n",
        "    def __init__(self, dataframe, image_dir, batch_size, transform, shuffle=True):\n",
        "        self.df = dataframe.reset_index(drop=True)\n",
        "        self.image_dir = image_dir\n",
        "        self.batch_size = batch_size\n",
        "        self.transform = transform\n",
        "        self.shuffle = shuffle\n",
        "        self.indices = np.arange(len(self.df))\n",
        "        self.on_epoch_end()\n",
        "\n",
        "    def __len__(self):\n",
        "        return int(np.ceil(len(self.df) / self.batch_size))\n",
        "\n",
        "    def on_epoch_end(self):\n",
        "        if self.shuffle:\n",
        "            np.random.shuffle(self.indices)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        # Get indices for the current batch\n",
        "        batch_indices = self.indices[idx * self.batch_size:(idx + 1) * self.batch_size]\n",
        "\n",
        "        batch_images = []\n",
        "        batch_labels = []\n",
        "\n",
        "        for i in batch_indices:\n",
        "            row = self.df.iloc[i]\n",
        "            file_name = row[\"file_name\"]\n",
        "            label = int(row[\"label\"])\n",
        "\n",
        "            # Construct image path and load image\n",
        "            img_path = os.path.join(self.image_dir, file_name)\n",
        "            img = cv2.imread(img_path)\n",
        "            img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "            # Apply transformations if provided\n",
        "            if self.transform:\n",
        "                augmented = self.transform(image=img)\n",
        "                img = augmented[\"image\"]\n",
        "\n",
        "            batch_images.append(img)\n",
        "            batch_labels.append(label)\n",
        "\n",
        "        # Convert lists to numpy arrays\n",
        "        batch_x = np.stack(batch_images, axis=0).astype(\"float32\")\n",
        "        batch_y = np.array(batch_labels, dtype=\"int32\")  # For sparse_categorical_crossentropy\n",
        "\n",
        "        return batch_x, batch_y\n",
        "\n",
        "# Define ImageNet mean and standard deviation for normalization\n",
        "imagenet_mean = (0.485, 0.456, 0.406)\n",
        "imagenet_std  = (0.229, 0.224, 0.225)\n",
        "\n",
        "# Define training image transformations with data augmentation\n",
        "train_transform = A.Compose([\n",
        "    A.Resize(224, 224),\n",
        "    A.HorizontalFlip(p=0.5),\n",
        "    A.RandomBrightnessContrast(p=0.5),\n",
        "    A.Affine(\n",
        "    scale=(1-0.1, 1+0.1),\n",
        "    translate_percent=(0.05, 0.05),\n",
        "    rotate=(-15, 15),\n",
        "    p=0.5),\n",
        "    A.GaussNoise(p=0.3),\n",
        "    A.Normalize(mean=imagenet_mean, std=imagenet_std),\n",
        "])\n",
        "\n",
        "# Define validation image transformations (resizing and normalization only)\n",
        "val_transform = A.Compose([\n",
        "    A.Resize(224, 224),\n",
        "    A.Normalize(mean=imagenet_mean, std=imagenet_std),\n",
        "])\n",
        "\n",
        "# Reload the dataframes to ensure they are available\n",
        "try:\n",
        "    train_df = pd.read_csv(f'{dataset_base_path}/train.csv')\n",
        "    test_df = pd.read_csv(f'{dataset_base_path}/test_refined.csv')\n",
        "    val_df = pd.read_csv(f'{dataset_base_path}/val.csv')\n",
        "    print(\"DataFrames reloaded for cross-validation.\")\n",
        "except FileNotFoundError as e:\n",
        "    print(f\"Error reloading dataframes: {e}. Please ensure the dataset is unzipped and available at '{dataset_base_path}/'.\")\n",
        "    # Exit or handle error appropriately if files are missing\n",
        "    # In a notebook context, we'll just print and continue, assuming previous steps were successful.\n",
        "\n",
        "# Define image directories\n",
        "train_image_dir = f'{dataset_base_path}/train'\n",
        "val_image_dir = f'{dataset_base_path}/val' # For final ensemble validation\n",
        "\n",
        "BATCH_SIZE = 32\n",
        "NUM_CLASSES = 5\n",
        "\n",
        "# Main validation generator for ensemble prediction later\n",
        "main_val_gen = AlbumentationsSequence(\n",
        "    val_df, val_image_dir,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    transform=val_transform,\n",
        "    shuffle=False\n",
        ")\n",
        "# True labels for the main validation set\n",
        "main_y_true = val_df['label'].values\n",
        "print(\"Main validation data generator and true labels prepared for ensemble prediction.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ruhPxhF-zWGv"
      },
      "source": [
        "### Initial Cross Validation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bcCmIwAM_FOn",
        "outputId": "4f090ae8-667c-4e57-8a81-1a7b081e26cd"
      },
      "outputs": [],
      "source": [
        "# --- Cross-Validation Setup ---\n",
        "# Number of epochs for each fold during initial CV training\n",
        "EPOCHS_CV = 5\n",
        "# Number of splits for StratifiedKFold\n",
        "K = 3\n",
        "# Initialize StratifiedKFold for maintaining class distribution across folds\n",
        "skf = StratifiedKFold(n_splits=K, shuffle=True, random_state=42)\n",
        "\n",
        "# Prepare data for K-Fold splitting\n",
        "X_train_cv = train_df['file_name'].values\n",
        "y_train_cv = train_df['label'].values\n",
        "\n",
        "# Lists to store results and model paths for later use\n",
        "fold_f1_scores = []\n",
        "cv_models_paths = [] # To store paths of best models from each fold\n",
        "\n",
        "print(\"\\n--- Starting Cross-Validation ---\")\n",
        "\n",
        "# Iterate through each fold\n",
        "for fold_idx, (train_idx, valid_idx) in enumerate(skf.split(X_train_cv, y_train_cv)):\n",
        "    print(f\"\\n=== Fold {fold_idx+1}/{K} ===\")\n",
        "\n",
        "    # a. Create dataframes for the current fold's training and validation sets\n",
        "    fold_train_df = train_df.iloc[train_idx].reset_index(drop=True)\n",
        "    fold_valid_df = train_df.iloc[valid_idx].reset_index(drop=True)\n",
        "\n",
        "    # b. Instantiate data generators for the current fold\n",
        "    fold_train_gen = AlbumentationsSequence(\n",
        "        fold_train_df, train_image_dir,\n",
        "        batch_size=BATCH_SIZE,\n",
        "        transform=train_transform,\n",
        "        shuffle=True\n",
        "    )\n",
        "\n",
        "    fold_valid_gen = AlbumentationsSequence(\n",
        "        fold_valid_df, train_image_dir, # Validation images for CV folds are also from 'train' folder\n",
        "        batch_size=BATCH_SIZE,\n",
        "        transform=val_transform,\n",
        "        shuffle=False\n",
        "    )\n",
        "\n",
        "    # c. Calculate class weights for the current fold's training data to address imbalance\n",
        "    fold_counts = fold_train_df['label'].value_counts().sort_index().values.astype('float32')\n",
        "    total_fold = fold_counts.sum()\n",
        "    fold_class_weights_array = total_fold / (NUM_CLASSES * fold_counts)\n",
        "    fold_class_weight = {i: float(w) for i, w in enumerate(fold_class_weights_array)}\n",
        "    print(\"Fold class weights:\", fold_class_weight)\n",
        "\n",
        "    # d. Initialize a fresh VGG16 model for this fold\n",
        "    base_model_cv = VGG16(\n",
        "        include_top=False,\n",
        "        weights='imagenet',\n",
        "        input_shape=(224, 224, 3)\n",
        "    )\n",
        "    base_model_cv.trainable = False # Start by training only the new top layers\n",
        "\n",
        "    # e. Build a new classification head on top of the VGG16 base\n",
        "    inputs_cv = layers.Input(shape=(224, 224, 3))\n",
        "    x_cv = base_model_cv(inputs_cv, training=False) # Important: set training=False when using frozen base_model\n",
        "    x_cv = layers.GlobalAveragePooling2D()(x_cv)\n",
        "    x_cv = layers.Dropout(0.3)(x_cv)\n",
        "    outputs_cv = layers.Dense(NUM_CLASSES, activation='softmax')(x_cv)\n",
        "\n",
        "    cv_model = models.Model(inputs_cv, outputs_cv)\n",
        "\n",
        "    # f. Compile the cross-validation model\n",
        "    cv_model.compile(\n",
        "        optimizer='adam',\n",
        "        loss='sparse_categorical_crossentropy',\n",
        "        metrics=['accuracy']\n",
        "    )\n",
        "    print(\"Fresh VGG16 model initialized and compiled for the current fold.\")\n",
        "\n",
        "    # g. ModelCheckpoint for the current fold to save the best model\n",
        "    checkpoint_filepath = f'vgg16_cv_fold_{fold_idx+1}_best.keras'\n",
        "    cv_checkpoint_callback = ModelCheckpoint(\n",
        "        filepath=checkpoint_filepath,\n",
        "        monitor='val_loss', # Monitor validation loss for best model\n",
        "        mode='min',\n",
        "        save_best_only=True,\n",
        "        save_weights_only=False,\n",
        "        verbose=1\n",
        "    )\n",
        "    cv_models_paths.append(checkpoint_filepath) # Store path for ensembling later\n",
        "\n",
        "    # h. Train the cross-validation model for a specified number of epochs\n",
        "    print(f\"Training Fold {fold_idx+1} model for {EPOCHS_CV} epochs...\")\n",
        "    cv_model.fit(\n",
        "        fold_train_gen,\n",
        "        validation_data=fold_valid_gen,\n",
        "        epochs=EPOCHS_CV,\n",
        "        class_weight=fold_class_weight,\n",
        "        callbacks=[cv_checkpoint_callback],\n",
        "        verbose=1\n",
        "    )\n",
        "\n",
        "    # i. Load the best model from this fold for evaluation\n",
        "    best_fold_model = tf.keras.models.load_model(checkpoint_filepath)\n",
        "\n",
        "    # j. Predict on the fold's validation set and convert probabilities to class labels\n",
        "    fold_probs = best_fold_model.predict(fold_valid_gen)\n",
        "    fold_pred = np.argmax(fold_probs, axis=1)\n",
        "    fold_y_true = fold_valid_df['label'].values\n",
        "\n",
        "    # k. Calculate the macro F1-score for the fold\n",
        "    fold_f1 = f1_score(fold_y_true, fold_pred, average='macro')\n",
        "    print(f\"Fold {fold_idx+1} F1 (macro) on its validation set: {fold_f1}\")\n",
        "    fold_f1_scores.append(fold_f1)\n",
        "\n",
        "print(\"\\n--- Cross-Validation Complete ---\")\n",
        "print(\"CV F1 (macro) per fold:\", fold_f1_scores)\n",
        "print(\"Mean CV F1 (macro):\","
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "89enO9R20cUf"
      },
      "source": [
        "### Cross Validation + Finetune"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 180
        },
        "id": "VR2F4_9uObe0",
        "outputId": "f59afe8b-a5ce-4aab-b4fb-5591d7d4b8ce"
      },
      "outputs": [],
      "source": [
        "from google.colab import files\n",
        "\n",
        "# Upload the saved Keras models from the initial cross-validation stage\n",
        "uploaded = files.upload()\n",
        "print(\"Uploaded files:\", list(uploaded.keys()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "csoKH8SzOe_t"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.metrics import f1_score\n",
        "\n",
        "# Define paths to the best models from the first cross-validation stage\n",
        "cv_stage1_paths = [\n",
        "    'vgg16_cv_fold_1_best.keras',\n",
        "    'vgg16_cv_fold_2_best.keras',\n",
        "    'vgg16_cv_fold_3_best.keras',\n",
        "]\n",
        "\n",
        "K = len(cv_stage1_paths)  # Number of folds / models\n",
        "# Re-initialize StratifiedKFold to ensure consistent splits with initial CV\n",
        "skf = StratifiedKFold(n_splits=K, shuffle=True, random_state=42)\n",
        "\n",
        "# Prepare training data for K-Fold splitting\n",
        "X_train_cv = train_df['file_name'].values\n",
        "y_train_cv = train_df['label'].values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qIJNF5s61Btk",
        "outputId": "0fdc71e1-f8bb-449c-f99f-a8e9d3fc1a23"
      },
      "outputs": [],
      "source": [
        "EPOCHS_FINE_TUNE = 3   # Number of epochs for fine-tuning each fold (adjust based on GPU resources and performance)\n",
        "cv_finetuned_paths = []\n",
        "cv_finetuned_f1_scores = []\n",
        "\n",
        "print(\"\\n--- Fine-tuning existing CV models (starting from saved .keras) ---\")\n",
        "\n",
        "# Iterate through each fold's split and its corresponding saved model path\n",
        "for fold_idx, ((train_idx, valid_idx), ckpt_path) in enumerate(zip(skf.split(X_train_cv, y_train_cv), cv_stage1_paths), start=1):\n",
        "    print(f\"\\n=== Fold {fold_idx}/{K} ===\")\n",
        "    print(f\"Using checkpoint: {ckpt_path}\")\n",
        "\n",
        "    # a. Recreate fold train/val splits based on the stored indices\n",
        "    fold_train_df = train_df.iloc[train_idx].reset_index(drop=True)\n",
        "    fold_valid_df = train_df.iloc[valid_idx].reset_index(drop=True)\n",
        "\n",
        "    # Instantiate data generators for the current fold's fine-tuning\n",
        "    fold_train_gen = AlbumentationsSequence(\n",
        "        fold_train_df, train_image_dir,\n",
        "        batch_size=BATCH_SIZE,\n",
        "        transform=train_transform,\n",
        "        shuffle=True\n",
        "    )\n",
        "\n",
        "    fold_valid_gen = AlbumentationsSequence(\n",
        "        fold_valid_df, train_image_dir,\n",
        "        batch_size=BATCH_SIZE,\n",
        "        transform=val_transform,\n",
        "        shuffle=False\n",
        "    )\n",
        "\n",
        "    # b. Calculate class weights for this fold's training data\n",
        "    fold_counts = fold_train_df['label'].value_counts().sort_index().values.astype('float32')\n",
        "    total_fold = fold_counts.sum()\n",
        "    fold_class_weights_array = total_fold / (NUM_CLASSES * fold_counts)\n",
        "    fold_class_weight = {i: float(w) for i, w in enumerate(fold_class_weights_array)}\n",
        "    print(\"Fold class weights:\", fold_class_weight)\n",
        "\n",
        "    # c. Load the existing (frozen-head trained) model for this fold\n",
        "    model_fold = tf.keras.models.load_model(ckpt_path)\n",
        "    print(\"Loaded fold model from checkpoint.\")\n",
        "\n",
        "    # d. Find the VGG16 base model within the loaded model\n",
        "    vgg16_base = None\n",
        "    for layer in model_fold.layers:\n",
        "        if 'vgg16' in layer.name.lower():\n",
        "            vgg16_base = layer\n",
        "            break\n",
        "\n",
        "    if vgg16_base is None:\n",
        "        raise ValueError(\"VGG16 base model not found in loaded fold model.\")\n",
        "\n",
        "    # e. Unfreeze only blocks 3, 4, and 5 of the VGG16 base for fine-tuning\n",
        "    vgg16_base.trainable = True\n",
        "    for layer in vgg16_base.layers:\n",
        "        if any(block in layer.name for block in ['block3', 'block4', 'block5']):\n",
        "            layer.trainable = True\n",
        "        else:\n",
        "            layer.trainable = False\n",
        "\n",
        "    # f. Recompile the model for fine-tuning with a small learning rate\n",
        "    model_fold.compile(\n",
        "        optimizer=tf.keras.optimizers.Adam(learning_rate=1e-5),\n",
        "        loss='sparse_categorical_crossentropy',\n",
        "        metrics=['accuracy']\n",
        "    )\n",
        "    print(\"Model recompiled for fine-tuning (blocks 3â€“5 trainable, lr=1e-5).\")\n",
        "\n",
        "    # g. Create a ModelCheckpoint for saving the best fine-tuned version of this fold\n",
        "    finetuned_ckpt_path = f'vgg16_cv_fold_{fold_idx}_finetuned_best.keras'\n",
        "    fine_ckpt = tf.keras.callbacks.ModelCheckpoint(\n",
        "        filepath=finetuned_ckpt_path,\n",
        "        monitor='val_loss',\n",
        "        mode='min',\n",
        "        save_best_only=True,\n",
        "        save_weights_only=False,\n",
        "        verbose=1\n",
        "    )\n",
        "\n",
        "    # h. Fine-tune the model on this fold's data\n",
        "    print(f\"Fine-tuning Fold {fold_idx} for {EPOCHS_FINE_TUNE} epochs...\")\n",
        "    model_fold.fit(\n",
        "        fold_train_gen,\n",
        "        validation_data=fold_valid_gen,\n",
        "        epochs=EPOCHS_FINE_TUNE,\n",
        "        class_weight=fold_class_weight,\n",
        "        callbacks=[fine_ckpt],\n",
        "        verbose=1\n",
        "    )\n",
        "\n",
        "    # i. Load the best fine-tuned model and evaluate its F1 macro score on the fold's validation set\n",
        "    best_fold_model = tf.keras.models.load_model(finetuned_ckpt_path)\n",
        "    cv_finetuned_paths.append(finetuned_ckpt_path)\n",
        "\n",
        "    fold_probs = best_fold_model.predict(fold_valid_gen, verbose=0)\n",
        "    fold_pred = np.argmax(fold_probs, axis=1)\n",
        "    fold_y_true = fold_valid_df['label'].values\n",
        "\n",
        "    fold_f1 = f1_score(fold_y_true, fold_pred, average='macro')\n",
        "    cv_finetuned_f1_scores.append(fold_f1)\n",
        "    print(f\"Fold {fold_idx} fine-tuned F1 (macro) on its validation set: {fold_f1:.4f}\")\n",
        "\n",
        "print(\"\\n--- Fine-tuning of CV folds complete ---\")\n",
        "print(\"Fine-tuned CV F1 (macro) per fold:\", cv_finetuned_f1_scores)\n",
        "print(\"Mean fine-tuned CV F1 (macro):\", np.mean(cv_finetuned_f1_scores))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3Pfj8PATziyB"
      },
      "source": [
        "## Ensemble"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uMSzNJBU_HKa"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "\n",
        "# Function to perform ensemble prediction across multiple models\n",
        "def ensemble_predict(model_paths, generator):\n",
        "    \"\"\"\n",
        "    Performs ensemble prediction by loading models and averaging their probabilities.\n",
        "\n",
        "    Args:\n",
        "        model_paths (list): A list of file paths to the Keras models (.keras format).\n",
        "        generator (tf.keras.utils.Sequence): A data generator for predictions.\n",
        "\n",
        "    Returns:\n",
        "        numpy.ndarray: Averaged probabilities from all successfully loaded models.\n",
        "    \"\"\"\n",
        "    all_probs = None\n",
        "    loaded_models = []\n",
        "    print(f\"Loading {len(model_paths)} models for ensembling...\")\n",
        "    for path in model_paths:\n",
        "        try:\n",
        "            m = tf.keras.models.load_model(path)\n",
        "            loaded_models.append(m)\n",
        "            print(f\"Loaded model: {path}\")\n",
        "        except Exception as e:\n",
        "            print(f\"Error loading model {path}: {e}. Skipping this model.\")\n",
        "\n",
        "    if not loaded_models:\n",
        "        raise ValueError(\"No models were successfully loaded for ensembling.\")\n",
        "\n",
        "    print(f\"Making predictions with {len(loaded_models)} loaded models...\")\n",
        "    for i, m in enumerate(loaded_models):\n",
        "        print(f\"Predicting with model {i+1}/{len(loaded_models)}...\")\n",
        "        # Use verbose=0 to suppress prediction progress bars for cleaner output\n",
        "        probs = m.predict(generator, verbose=0)\n",
        "        if all_probs is None:\n",
        "            all_probs = probs\n",
        "        else:\n",
        "            all_probs += probs\n",
        "    all_probs /= len(loaded_models)\n",
        "    return all_probs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0l_lHQLtP3uK"
      },
      "outputs": [],
      "source": [
        "# Assign the list of fine-tuned CV model paths to cv_models_paths\n",
        "cv_models_paths = cv_finetuned_paths"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RLqsIy8KFiLV",
        "outputId": "ede8eb37-70ce-4a2b-afcc-30e3b8199924"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import f1_score\n",
        "import numpy as np\n",
        "\n",
        "print(\"\\n--- Starting Ensemble Prediction (fine-tuned + CV models) ---\")\n",
        "\n",
        "# Path to previously trained fine-tuned model (if used in ensemble)\n",
        "# fine_tuned_model_path = 'vgg16_fine_tuned_best.keras'\n",
        "\n",
        "# Combine fine-tuned model + all CV models (if fine_tuned_model_path was included)\n",
        "# ensemble_model_paths = [fine_tuned_model_path] + cv_models_paths\n",
        "\n",
        "# Use only the fine-tuned CV models for this ensemble\n",
        "ensemble_model_paths = cv_models_paths\n",
        "\n",
        "print(\"Models used in ensemble:\")\n",
        "for p in ensemble_model_paths:\n",
        "    print(\" -\", p)\n",
        "\n",
        "# Perform ensemble prediction on the main validation set\n",
        "print(\"\\nEnsembling fine-tuned + CV models on main validation set...\")\n",
        "ens_probs = ensemble_predict(ensemble_model_paths, main_val_gen)\n",
        "ens_pred = np.argmax(ens_probs, axis=1)\n",
        "\n",
        "# Calculate and print the macro F1-score for the ensemble on the validation set\n",
        "f1_macro_ens = f1_score(main_y_true, ens_pred, average='macro')\n",
        "print(f\"\\nEnsemble Validation F1 (macro): {f1_macro_ens:.4f}\")\n",
        "\n",
        "print(\"\\n--- Ensemble Prediction Complete ---\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LBjY5Z4u_NWS"
      },
      "source": [
        "# Step 4: Test"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d-rmbfll3U8p"
      },
      "source": [
        "## FineTuned"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lUQxDeYW_OvK",
        "outputId": "4a4daa25-401c-4594-c057-1b6fa6d47903"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import os\n",
        "import cv2\n",
        "import albumentations as A\n",
        "from sklearn.metrics import f1_score, classification_report\n",
        "\n",
        "# Define the base path for the dataset\n",
        "dataset_base_path = '/content/cpe342-karena/public_dataset/task4'\n",
        "\n",
        "# Re-define AlbumentationsSequence class to ensure it's available and robust for test set\n",
        "class AlbumentationsSequence(tf.keras.utils.Sequence):\n",
        "    def __init__(self, dataframe, image_dir, batch_size, transform, shuffle=True, is_test=False):\n",
        "        self.df = dataframe.reset_index(drop=True)\n",
        "        self.image_dir = image_dir\n",
        "        self.batch_size = batch_size\n",
        "        self.transform = transform\n",
        "        self.shuffle = shuffle\n",
        "        self.is_test = is_test # Flag to indicate if this is a test generator (no labels needed)\n",
        "        self.indices = np.arange(len(self.df))\n",
        "        self.on_epoch_end()\n",
        "\n",
        "    def __len__(self):\n",
        "        return int(np.ceil(len(self.df) / self.batch_size))\n",
        "\n",
        "    def on_epoch_end(self):\n",
        "        if self.shuffle:\n",
        "            np.random.shuffle(self.indices)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        # Get indices for the current batch\n",
        "        batch_indices = self.indices[idx * self.batch_size:(idx + 1) * self.batch_size]\n",
        "\n",
        "        batch_images = []\n",
        "        batch_labels = []\n",
        "\n",
        "        for i in batch_indices:\n",
        "            row = self.df.iloc[i]\n",
        "            file_name = row[\"file_name\"]\n",
        "\n",
        "            # Construct image path and load image\n",
        "            img_path = os.path.join(self.image_dir, file_name)\n",
        "            img = cv2.imread(img_path)\n",
        "            img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "            # Apply transformations if provided\n",
        "            if self.transform:\n",
        "                augmented = self.transform(image=img)\n",
        "                img = augmented[\"image\"]\n",
        "\n",
        "            batch_images.append(img)\n",
        "            if not self.is_test:\n",
        "                label = int(row[\"label\"])\n",
        "                batch_labels.append(label)\n",
        "\n",
        "        # Convert lists to numpy arrays\n",
        "        batch_x = np.stack(batch_images, axis=0).astype(\"float32\")\n",
        "\n",
        "        if self.is_test:\n",
        "            return batch_x\n",
        "        else:\n",
        "            batch_y = np.array(batch_labels, dtype=\"int32\")\n",
        "            return batch_x, batch_y\n",
        "\n",
        "# Define ImageNet mean and standard deviation for normalization\n",
        "imagenet_mean = (0.485, 0.456, 0.406)\n",
        "imagenet_std  = (0.229, 0.224, 0.225)\n",
        "\n",
        "# Define validation/test image transformations (resizing and normalization only)\n",
        "val_transform = A.Compose([\n",
        "    A.Resize(224, 224),\n",
        "    A.Normalize(mean=imagenet_mean, std=imagenet_std),\n",
        "])\n",
        "\n",
        "# Reload test_df to ensure it's available, using the refined test_refined.csv\n",
        "try:\n",
        "    test_df = pd.read_csv(f'{dataset_base_path}/test_refined.csv')\n",
        "    print(\"test_df reloaded.\")\n",
        "except FileNotFoundError as e:\n",
        "    print(f\"Error reloading test_df: {e}. Please ensure the dataset is unzipped and available at '{dataset_base_path}/'.\")\n",
        "    # Exit or handle error appropriately if files are missing\n",
        "    exit()\n",
        "\n",
        "# Define image directory for the test set\n",
        "test_image_dir = f'{dataset_base_path}/test'\n",
        "BATCH_SIZE = 32\n",
        "\n",
        "# 1. Load the best fine-tuned model saved from previous steps\n",
        "fine_tuned_model = tf.keras.models.load_model('vgg16_fine_tuned_best.keras')\n",
        "print(\"Successfully loaded the best fine-tuned model: vgg16_fine_tuned_best.keras\")\n",
        "\n",
        "# 2. Prepare a data generator for the test_df using val_transform\n",
        "test_gen = AlbumentationsSequence(\n",
        "    test_df,\n",
        "    test_image_dir,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    transform=val_transform,\n",
        "    shuffle=False, # Important for maintaining order for submission file\n",
        "    is_test=True # Indicate this is a test generator without labels\n",
        ")\n",
        "print(\"Test data generator prepared.\")\n",
        "\n",
        "# 3. Generate predictions on the test set using the fine-tuned model\n",
        "print(\"Generating predictions on the test set...\")\n",
        "test_probabilities = fine_tuned_model.predict(test_gen)\n",
        "\n",
        "# 4. Convert predicted probabilities to class labels (0-4)\n",
        "test_predictions = np.argmax(test_probabilities, axis=1)\n",
        "print(\"Predictions generated and converted to class labels.\")\n",
        "\n",
        "# 5. Create the submission DataFrame in the required format\n",
        "submission_df = pd.DataFrame({\n",
        "    'id': test_df['id'],\n",
        "    'label': test_predictions\n",
        "})\n",
        "\n",
        "# 6. Save the predictions to a CSV file for submission\n",
        "submission_file_path = 'submission.csv'\n",
        "submission_df.to_csv(submission_file_path, index=False)\n",
        "\n",
        "print(f\"\\nPredictions saved to {submission_file_path}\")\n",
        "print(\"Submission file head:\")\n",
        "print(submission_df.head())\n",
        "print(\"\\nPrediction on test set completed.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8Vh2jU1b3c2b"
      },
      "source": [
        "## Ensemble"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "collapsed": true,
        "id": "4cEU4serTRJH",
        "outputId": "4ebd80e5-a21f-46a0-e88b-f426154e2b61"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import os\n",
        "import cv2\n",
        "import albumentations as A\n",
        "from sklearn.metrics import f1_score, classification_report\n",
        "\n",
        "# Define the base path for the dataset\n",
        "dataset_base_path = '/content/cpe342-karena/public_dataset/task4'\n",
        "\n",
        "# Re-define AlbumentationsSequence class to ensure it's available and robust for test set\n",
        "class AlbumentationsSequence(tf.keras.utils.Sequence):\n",
        "    def __init__(self, dataframe, image_dir, batch_size, transform, shuffle=True, is_test=False):\n",
        "        self.df = dataframe.reset_index(drop=True)\n",
        "        self.image_dir = image_dir\n",
        "        self.batch_size = batch_size\n",
        "        self.transform = transform\n",
        "        self.shuffle = shuffle\n",
        "        self.is_test = is_test # Flag to indicate if this is a test generator (no labels needed)\n",
        "        self.indices = np.arange(len(self.df))\n",
        "        self.on_epoch_end()\n",
        "\n",
        "    def __len__(self):\n",
        "        return int(np.ceil(len(self.df) / self.batch_size))\n",
        "\n",
        "    def on_epoch_end(self):\n",
        "        if self.shuffle:\n",
        "            np.random.shuffle(self.indices)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        # Get indices for the current batch\n",
        "        batch_indices = self.indices[idx * self.batch_size:(idx + 1) * self.batch_size]\n",
        "\n",
        "        batch_images = []\n",
        "        batch_labels = []\n",
        "\n",
        "        for i in batch_indices:\n",
        "            row = self.df.iloc[i]\n",
        "            file_name = row[\"file_name\"]\n",
        "\n",
        "            # Construct image path and load image\n",
        "            img_path = os.path.join(self.image_dir, file_name)\n",
        "            img = cv2.imread(img_path)\n",
        "            img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "            # Apply transformations if provided\n",
        "            if self.transform:\n",
        "                augmented = self.transform(image=img)\n",
        "                img = augmented[\"image\"]\n",
        "\n",
        "            batch_images.append(img)\n",
        "            if not self.is_test:\n",
        "                label = int(row[\"label\"])\n",
        "                batch_labels.append(label)\n",
        "\n",
        "        # Convert lists to numpy arrays\n",
        "        batch_x = np.stack(batch_images, axis=0).astype(\"float32\")\n",
        "\n",
        "        if self.is_test:\n",
        "            return batch_x\n",
        "        else:\n",
        "            batch_y = np.array(batch_labels, dtype=\"int32\")\n",
        "            return batch_x, batch_y\n",
        "\n",
        "# Define ImageNet mean and standard deviation for normalization\n",
        "imagenet_mean = (0.485, 0.456, 0.406)\n",
        "imagenet_std  = (0.229, 0.224, 0.225)\n",
        "\n",
        "# Define validation/test image transformations (resizing and normalization only)\n",
        "val_transform = A.Compose([\n",
        "    A.Resize(224, 224),\n",
        "    A.Normalize(mean=imagenet_mean, std=imagenet_std),\n",
        "])\n",
        "\n",
        "# Reload test_df to ensure it's available\n",
        "try:\n",
        "    test_df = pd.read_csv(f'{dataset_base_path}/test_refined.csv')\n",
        "    print(\"test_df reloaded.\")\n",
        "except FileNotFoundError as e:\n",
        "    print(f\"Error reloading test_df: {e}. Please ensure the dataset is unzipped and available at '{dataset_base_path}/'.\")\n",
        "    # Exit or handle error appropriately if files are missing\n",
        "    exit()\n",
        "\n",
        "# Define image directory for the test set\n",
        "test_image_dir = f'{dataset_base_path}/test'\n",
        "BATCH_SIZE = 32\n",
        "\n",
        "# 2. Prepare a data generator for the test_df using val_transform\n",
        "test_gen = AlbumentationsSequence(\n",
        "    test_df,\n",
        "    test_image_dir,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    transform=val_transform,\n",
        "    shuffle=False, # Important for maintaining order for submission\n",
        "    is_test=True # Indicate this is a test generator without labels\n",
        ")\n",
        "print(\"Test data generator prepared.\")\n",
        "\n",
        "# Re-initialize `ensemble_model_paths` to the correct list from previous cells.\n",
        "# This ensures the `ensemble_predict` function receives a list of model paths,\n",
        "# not a single string or an improperly formatted variable.\n",
        "ensemble_model_paths = cv_finetuned_paths # Assuming cv_finetuned_paths holds the correct list of fine-tuned CV models\n",
        "\n",
        "# 3. Generate ensemble predictions on the test set\n",
        "print(\"\\nGenerating ensemble predictions on the test set...\")\n",
        "try:\n",
        "    test_probabilities = ensemble_predict(ensemble_model_paths, test_gen)\n",
        "except ValueError as e:\n",
        "    print(f\"Ensemble prediction failed: {e}. Please check 'ensemble_model_paths'.\")\n",
        "    # If ensemble prediction fails, create a dummy submission to avoid blocking further execution\n",
        "    submission_df = pd.DataFrame({'id': test_df['id'], 'label': -1}) # -1 can indicate an error or unknown label\n",
        "    submission_file_path = 'submission_ensemble_error.csv'\n",
        "    submission_df.to_csv(submission_file_path, index=False)\n",
        "    print(f\"Generated error submission file: {submission_file_path}\")\n",
        "    exit() # Stop execution after error\n",
        "\n",
        "# 4. Convert ensemble probabilities to class labels\n",
        "test_predictions = np.argmax(test_probabilities, axis=1)\n",
        "print(\"Ensemble predictions generated and converted to class labels.\")\n",
        "\n",
        "# 5. Create the submission DataFrame\n",
        "submission_df = pd.DataFrame({\n",
        "    'id': test_df['id'],\n",
        "    'label': test_predictions\n",
        "})\n",
        "\n",
        "# 6. Save the predictions to a CSV file\n",
        "submission_file_path = 'submission_ensemble.csv'\n",
        "submission_df.to_csv(submission_file_path, index=False)\n",
        "\n",
        "print(f\"\\nEnsemble predictions saved to {submission_file_path}\")\n",
        "print(\"Submission file head:\")\n",
        "print(submission_df.head())\n",
        "print(\"\\nEnsemble prediction on test set completed.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vchf0_wWYpZL"
      },
      "source": [
        "# VIT"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6ed950b2"
      },
      "source": [
        "# Step 5: ViT Model Setup and Utilities"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KWr-JlrkYoK7"
      },
      "outputs": [],
      "source": [
        "import keras_hub\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from keras import layers, models\n",
        "import keras_cv\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import cv2\n",
        "import os\n",
        "import albumentations as A\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.metrics import f1_score\n",
        "from tensorflow.keras.applications import VGG16\n",
        "import random\n",
        "\n",
        "# Set seeds for reproducibility\n",
        "SEED = 42\n",
        "tf.random.set_seed(SEED)\n",
        "np.random.seed(SEED)\n",
        "random.seed(SEED)\n",
        "\n",
        "# --- Albumentations Sequence for data loading and augmentation ---\n",
        "class AlbumentationsSequence(tf.keras.utils.Sequence):\n",
        "    def __init__(self, dataframe, image_dir, batch_size, transform, shuffle=True, is_test=False):\n",
        "        self.df = dataframe.reset_index(drop=True)\n",
        "        self.image_dir = image_dir\n",
        "        self.batch_size = batch_size\n",
        "        self.transform = transform\n",
        "        self.shuffle = shuffle\n",
        "        self.is_test = is_test\n",
        "        self.indices = np.arange(len(self.df))\n",
        "        self.on_epoch_end()\n",
        "\n",
        "    def __len__(self):\n",
        "        return int(np.ceil(len(self.df) / self.batch_size))\n",
        "\n",
        "    def on_epoch_end(self):\n",
        "        if self.shuffle:\n",
        "            np.random.shuffle(self.indices)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        # Get indices for the current batch\n",
        "        batch_indices = self.indices[idx * self.batch_size:(idx + 1) * self.batch_size]\n",
        "\n",
        "        batch_images = []\n",
        "        batch_labels = []\n",
        "\n",
        "        for i in batch_indices:\n",
        "            row = self.df.iloc[i]\n",
        "            file_name = row[\"file_name\"]\n",
        "\n",
        "            # Construct image path and load image\n",
        "            img_path = os.path.join(self.image_dir, file_name)\n",
        "            img = cv2.imread(img_path)\n",
        "            img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "            # Apply transformations if provided\n",
        "            if self.transform:\n",
        "                augmented = self.transform(image=img)\n",
        "                # Image should now be float32 in [0, 1] if ToFloat is used in transform\n",
        "                img = augmented[\"image\"]\n",
        "\n",
        "            batch_images.append(img)\n",
        "            if not self.is_test:\n",
        "                label = int(row[\"label\"])\n",
        "                batch_labels.append(label)\n",
        "\n",
        "        # Convert lists to numpy arrays\n",
        "        batch_x = np.stack(batch_images, axis=0).astype(\"float32\")\n",
        "\n",
        "        if self.is_test:\n",
        "            return batch_x\n",
        "        else:\n",
        "            batch_y = np.array(batch_labels, dtype=\"int32\")\n",
        "            return batch_x, batch_y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CeoQ_TioY2wO"
      },
      "outputs": [],
      "source": [
        "# Define the base path for the dataset\n",
        "dataset_base_path = '/content/cpe342-karena/public_dataset/task4'\n",
        "\n",
        "# --- Image transformations ---\n",
        "# - Remove manual ImageNet Normalize\n",
        "# - Use ToFloat so models see [0, 1]\n",
        "train_transform = A.Compose([\n",
        "    A.Resize(224, 224),\n",
        "    A.HorizontalFlip(p=0.5),\n",
        "    A.RandomBrightnessContrast(p=0.5),\n",
        "    A.Affine(\n",
        "        scale=(1 - 0.1, 1 + 0.1),\n",
        "        translate_percent=(0.05, 0.05),\n",
        "        rotate=(-15, 15),\n",
        "        p=0.5\n",
        "    ),\n",
        "    A.GaussNoise(p=0.3),\n",
        "    A.ToFloat(max_value=255.0),  # Normalize to float32 in [0, 1]\n",
        "])\n",
        "\n",
        "val_transform = A.Compose([\n",
        "    A.Resize(224, 224),\n",
        "    A.ToFloat(max_value=255.0),  # Normalize to float32 in [0, 1]\n",
        "])\n",
        "\n",
        "# --- Load dataframes ---\n",
        "try:\n",
        "    train_df = pd.read_csv(f'{dataset_base_path}/train.csv')\n",
        "    val_df = pd.read_csv(f'{dataset_base_path}/val.csv')\n",
        "    test_df = pd.read_csv(f'{dataset_base_path}/test_refined.csv')\n",
        "    print(\"DataFrames loaded successfully.\")\n",
        "except FileNotFoundError as e:\n",
        "    print(f\"Error loading dataframes: {e}. Please ensure the dataset is unzipped and available.\")\n",
        "    raise  # Stop execution if essential files are missing\n",
        "\n",
        "# Define image directories\n",
        "train_image_dir = f'{dataset_base_path}/train'\n",
        "val_image_dir = f'{dataset_base_path}/val'\n",
        "test_image_dir = f'{dataset_base_path}/test'\n",
        "\n",
        "# --- Global constants ---\n",
        "BATCH_SIZE = 32\n",
        "NUM_CLASSES = 5\n",
        "EPOCHS_CV_VIT_SWIN = 5  # Number of epochs for initial training of ViT/Swin heads\n",
        "K_FOLDS = 3             # Number of splits for StratifiedKFold\n",
        "\n",
        "# --- Ensemble predict function ---\n",
        "def ensemble_predict(model_paths, generator):\n",
        "    all_probs = None\n",
        "    loaded_models = []\n",
        "    for path in model_paths:\n",
        "        try:\n",
        "            m = tf.keras.models.load_model(path)\n",
        "            loaded_models.append(m)\n",
        "        except Exception as e:\n",
        "            print(f\"Error loading model {path}: {e}. Skipping this model.\")\n",
        "\n",
        "    if not loaded_models:\n",
        "        raise ValueError(\"No models were successfully loaded for ensembling.\")\n",
        "\n",
        "    print(f\"Making predictions with {len(loaded_models)} loaded models...\")\n",
        "    for i, m in enumerate(loaded_models):\n",
        "        probs = m.predict(generator, verbose=0)\n",
        "        if all_probs is None:\n",
        "            all_probs = probs\n",
        "        else:\n",
        "            all_probs += probs\n",
        "    all_probs /= len(loaded_models)\n",
        "    return all_probs\n",
        "\n",
        "# --- Main validation generator and cross-validation setup ---\n",
        "main_val_gen = AlbumentationsSequence(\n",
        "    val_df,\n",
        "    val_image_dir,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    transform=val_transform,\n",
        "    shuffle=False\n",
        ")\n",
        "main_y_true = val_df['label'].values\n",
        "print(\"Main validation data generator and true labels prepared for overall ensemble evaluation.\")\n",
        "\n",
        "# Setup for cross-validation\n",
        "X_train_cv = train_df['file_name'].values\n",
        "y_train_cv = train_df['label'].values\n",
        "skf = StratifiedKFold(n_splits=K_FOLDS, shuffle=True, random_state=42)\n",
        "\n",
        "# Cache splits so all models (VGG, ViT, Swin) use the same folds for consistency\n",
        "fold_splits = list(skf.split(X_train_cv, y_train_cv))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1b55f0c8"
      },
      "source": [
        "# Step 6: ViT Cross-Validation Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "615fTV_TY7QP"
      },
      "outputs": [],
      "source": [
        "# --- ViT Cross-Validation Training (Initial Head Training) ---\n",
        "vit_cv_finetuned_paths = []\n",
        "vit_cv_f1_scores = []\n",
        "print(\"\\n--- Starting ViT Cross-Validation Training ---\")\n",
        "\n",
        "# Iterate through each pre-defined fold split\n",
        "for fold_idx, (train_idx, valid_idx) in enumerate(fold_splits):\n",
        "    print(f\"\\n=== ViT Fold {fold_idx+1}/{K_FOLDS} ===\")\n",
        "\n",
        "    # Create dataframes for the current fold's training and validation sets\n",
        "    fold_train_df = train_df.iloc[train_idx].reset_index(drop=True)\n",
        "    fold_valid_df = train_df.iloc[valid_idx].reset_index(drop=True)\n",
        "\n",
        "    # Instantiate data generators for the current fold\n",
        "    fold_train_gen = AlbumentationsSequence(\n",
        "        fold_train_df,\n",
        "        train_image_dir,\n",
        "        batch_size=BATCH_SIZE,\n",
        "        transform=train_transform,\n",
        "        shuffle=True\n",
        "    )\n",
        "    fold_valid_gen = AlbumentationsSequence(\n",
        "        fold_valid_df,\n",
        "        train_image_dir,\n",
        "        batch_size=BATCH_SIZE,\n",
        "        transform=val_transform,\n",
        "        shuffle=False\n",
        "    )\n",
        "\n",
        "    # Calculate class weights for the current fold's training data\n",
        "    fold_counts = fold_train_df['label'].value_counts().sort_index().values.astype('float32')\n",
        "    total_fold = fold_counts.sum()\n",
        "    fold_class_weights_array = total_fold / (NUM_CLASSES * fold_counts)\n",
        "    fold_class_weight = {i: float(w) for i, w in enumerate(fold_class_weights_array)}\n",
        "    print(\"Fold class weights:\", fold_class_weight)\n",
        "\n",
        "    # Build a fresh ViT model (backbone frozen) for this fold\n",
        "    vit_model = build_vit_model(NUM_CLASSES)\n",
        "    print(\"Fresh ViT model initialized and compiled for the current fold.\")\n",
        "\n",
        "    # Define checkpoint filepath for this fold\n",
        "    checkpoint_filepath = f'vit_cv_fold_{fold_idx+1}_best.keras'\n",
        "    cv_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
        "        filepath=checkpoint_filepath,\n",
        "        monitor='val_loss',\n",
        "        mode='min',\n",
        "        save_best_only=True,\n",
        "        save_weights_only=False,\n",
        "        verbose=1\n",
        "    )\n",
        "\n",
        "    # Train the ViT model's classification head\n",
        "    print(f\"Training ViT Fold {fold_idx+1} model for {EPOCHS_CV_VIT_SWIN} epochs...\")\n",
        "    vit_model.fit(\n",
        "        fold_train_gen,\n",
        "        validation_data=fold_valid_gen,\n",
        "        epochs=EPOCHS_CV_VIT_SWIN,\n",
        "        class_weight=fold_class_weight,\n",
        "        callbacks=[cv_checkpoint_callback],\n",
        "        verbose=1\n",
        "    )\n",
        "\n",
        "    # Evaluate the best model from this fold\n",
        "    try:\n",
        "        best_fold_model = tf.keras.models.load_model(checkpoint_filepath)\n",
        "        vit_cv_finetuned_paths.append(checkpoint_filepath) # Store path for ensembling\n",
        "\n",
        "        fold_probs = best_fold_model.predict(fold_valid_gen, verbose=0)\n",
        "        fold_pred = np.argmax(fold_probs, axis=1)\n",
        "        fold_y_true = fold_valid_df['label'].values\n",
        "\n",
        "        fold_f1 = f1_score(fold_y_true, fold_pred, average='macro')\n",
        "        vit_cv_f1_scores.append(fold_f1)\n",
        "        print(f\"ViT Fold {fold_idx+1} F1 (macro) on its validation set: {fold_f1:.4f}\")\n",
        "    except Exception as e:\n",
        "        print(f\"Could not load or evaluate best ViT model for fold {fold_idx+1}: {e}. Appending current checkpoint path and F1 0.0.\")\n",
        "        vit_cv_finetuned_paths.append(checkpoint_filepath) # Still append path even if evaluation fails\n",
        "        vit_cv_f1_scores.append(0.0)\n",
        "\n",
        "print(\"\\n--- ViT Cross-Validation Training Complete ---\")\n",
        "print(\"ViT CV F1 (macro) per fold:\", vit_cv_f1_scores)\n",
        "print(\"Mean ViT CV F1 (macro):\")\n",
        "if vit_cv_f1_scores:\n",
        "    print(np.mean(vit_cv_f1_scores))\n",
        "else:\n",
        "    print(\"N/A (no scores to average)\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1e3361a4"
      },
      "source": [
        "# Step 7: Ensemble Setup for All CV Models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wIC6o1fhZC_B"
      },
      "outputs": [],
      "source": [
        "# --- Combine all model checkpoints for the final ensemble ---\n",
        "\n",
        "# Paths to the fine-tuned VGG16 models from cross-validation\n",
        "vgg16_cv_finetuned_paths = [\n",
        "    'vgg16_cv_fold_1_finetuned_best.keras',\n",
        "    'vgg16_cv_fold_2_finetuned_best.keras',\n",
        "    'vgg16_cv_fold_3_finetuned_best.keras',\n",
        "]\n",
        "\n",
        "# Combine VGG16 fine-tuned CV model paths with ViT fine-tuned CV model paths\n",
        "all_ensemble_model_paths = vgg16_cv_finetuned_paths + vit_cv_finetuned_paths\n",
        "\n",
        "print(f\"\\nTotal models in ensemble: {len(all_ensemble_model_paths)}\")\n",
        "print(\"All ensemble model paths collected:\")\n",
        "for path in all_ensemble_model_paths:\n",
        "    print(f\" - {path}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O0gfBFvaZG7a"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import f1_score\n",
        "import numpy as np\n",
        "\n",
        "# --- Ensemble Prediction on Validation Set ---\n",
        "print(\"\\n--- Starting Ensemble Prediction on Validation Set ---\")\n",
        "try:\n",
        "    # Perform ensemble prediction using all collected model paths on the main validation set\n",
        "    ensemble_val_probs = ensemble_predict(all_ensemble_model_paths, main_val_gen)\n",
        "    ensemble_val_pred = np.argmax(ensemble_val_probs, axis=1)\n",
        "\n",
        "    # Calculate the macro F1-score for the ensemble predictions\n",
        "    f1_macro_ensemble_val = f1_score(main_y_true, ensemble_val_pred, average='macro')\n",
        "    print(f\"\\nFinal Ensemble Validation F1 (macro): {f1_macro_ensemble_val:.4f}\")\n",
        "except ValueError as e:\n",
        "    print(f\"Ensemble prediction on validation set failed: {e}\")\n",
        "    f1_macro_ensemble_val = 0.0 # Set F1 to 0.0 if ensemble fails\n",
        "\n",
        "print(\"--- Ensemble Prediction on Validation Set Complete ---\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O7Ow94D_ZJSK"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# --- Ensemble Prediction on Test Set + Submission File Generation ---\n",
        "print(\"\\n--- Starting Ensemble Prediction on Test Set ---\")\n",
        "\n",
        "# Prepare a data generator specifically for the test set\n",
        "test_gen_ensemble = AlbumentationsSequence(\n",
        "    test_df,\n",
        "    test_image_dir,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    transform=val_transform,\n",
        "    shuffle=False,\n",
        "    is_test=True\n",
        ")\n",
        "\n",
        "try:\n",
        "    # Perform ensemble prediction on the test set\n",
        "    ensemble_test_probs = ensemble_predict(all_ensemble_model_paths, test_gen_ensemble)\n",
        "    ensemble_test_predictions = np.argmax(ensemble_test_probs, axis=1)\n",
        "    print(\"Ensemble predictions on test set generated.\")\n",
        "\n",
        "    # Create the final submission DataFrame\n",
        "    submission_df_final = pd.DataFrame({\n",
        "        'id': test_df['id'],\n",
        "        'label': ensemble_test_predictions\n",
        "    })\n",
        "\n",
        "    # Define the submission file path and save the DataFrame to CSV\n",
        "    submission_file_path_final = 'submission_final_ensemble.csv'\n",
        "    submission_df_final.to_csv(submission_file_path_final, index=False)\n",
        "\n",
        "    print(f\"\\nFinal Ensemble predictions saved to {submission_file_path_final}\")\n",
        "    print(\"Submission file head:\")\n",
        "    print(submission_df_final.head())\n",
        "except ValueError as e:\n",
        "    print(f\"Ensemble prediction on test set failed: {e}\")\n",
        "    # If prediction fails, create an error submission file\n",
        "    submission_df_final = pd.DataFrame({'id': test_df['id'], 'label': -1})\n",
        "    submission_file_path_final = 'submission_final_ensemble_error.csv'\n",
        "    submission_df_final.to_csv(submission_file_path_final, index=False)\n",
        "    print(f\"Generated error submission file: {submission_file_path_final}\")\n",
        "\n",
        "print(\"--- Ensemble Prediction on Test Set Complete ---\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ahoJ9NY3ZbjS"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import f1_score\n",
        "import numpy as np\n",
        "from tensorflow import keras\n",
        "import pandas as pd\n",
        "\n",
        "# Define the base path for the dataset (for test_df)\n",
        "dataset_base_path = '/content/cpe342-karena/public_dataset/task4'\n",
        "\n",
        "# Reload test_df to ensure it's available and consistent\n",
        "try:\n",
        "    test_df = pd.read_csv(f'{dataset_base_path}/test_refined.csv')\n",
        "    print(\"test_df reloaded for ensemble evaluation.\")\n",
        "except FileNotFoundError as e:\n",
        "    print(f\"Error reloading test_df: {e}. Please ensure the dataset is unzipped.\")\n",
        "    # If test_df is critical and missing, exit or handle appropriately\n",
        "    exit()\n",
        "\n",
        "# --- ViT alone: validate + test submission ---\n",
        "print(\"\\n=== ViT: evaluation on val + prediction on test ===\")\n",
        "\n",
        "# Make predictions with the best fine-tuned ViT model on the validation set\n",
        "vit_val_probs = vit_best.predict(val_gen, verbose=0)\n",
        "vit_val_pred = np.argmax(vit_val_probs, axis=1)\n",
        "vit_val_f1 = f1_score(y_val_true, vit_val_pred, average=\"macro\")\n",
        "print(f\"ViT Validation F1 (macro): {vit_val_f1:.4f}\")\n",
        "\n",
        "# Make predictions with the best fine-tuned ViT model on the test set\n",
        "vit_test_probs = vit_best.predict(test_gen, verbose=0)\n",
        "vit_test_pred = np.argmax(vit_test_probs, axis=1)\n",
        "\n",
        "# Create and save ViT-only submission file\n",
        "submission_vit = pd.DataFrame({\n",
        "    \"id\": test_df[\"id\"],\n",
        "    \"label\": vit_test_pred\n",
        "})\n",
        "submission_vit_path = \"submission_vit_only.csv\"\n",
        "submission_vit.to_csv(submission_vit_path, index=False)\n",
        "print(f\"Saved ViT-only submission to {submission_vit_path}\")\n",
        "print(submission_vit.head())\n",
        "\n",
        "\n",
        "# --- VGG ensemble: validate + test ---\n",
        "print(\"\\n=== VGG (CV models) ensemble on val + test ===\")\n",
        "\n",
        "# Paths to the fine-tuned VGG models from cross-validation\n",
        "vgg_paths = [\n",
        "    \"vgg16_cv_fold_1_finetuned_best.keras\",\n",
        "    \"vgg16_cv_fold_2_finetuned_best.keras\",\n",
        "    \"vgg16_cv_fold_3_finetuned_best.keras\",\n",
        "]\n",
        "\n",
        "# Helper function to predict with an ensemble of models\n",
        "def predict_ensemble(paths, generator):\n",
        "    all_probs = None\n",
        "    num_used = 0\n",
        "\n",
        "    for path in paths:\n",
        "        try:\n",
        "            model = keras.models.load_model(path)\n",
        "        except Exception as e:\n",
        "            print(f\"Could not load {path}: {e}. Skipping.\")\n",
        "            continue\n",
        "\n",
        "        probs = model.predict(generator, verbose=0)\n",
        "        if all_probs is None:\n",
        "            all_probs = probs\n",
        "        else:\n",
        "            all_probs += probs\n",
        "\n",
        "        num_used += 1\n",
        "\n",
        "    if num_used == 0:\n",
        "        raise ValueError(\"No models successfully loaded for ensemble.\")\n",
        "\n",
        "    all_probs /= num_used\n",
        "    return all_probs\n",
        "\n",
        "# Make predictions with the VGG ensemble on the validation set\n",
        "vgg_val_probs = predict_ensemble(vgg_paths, val_gen)\n",
        "vgg_val_pred = np.argmax(vgg_val_probs, axis=1)\n",
        "vgg_val_f1 = f1_score(y_val_true, vgg_val_pred, average=\"macro\")\n",
        "print(f\"VGG CV Ensemble Validation F1 (macro): {vgg_val_f1:.4f}\")\n",
        "\n",
        "# Make predictions with the VGG ensemble on the test set\n",
        "vgg_test_probs = predict_ensemble(vgg_paths, test_gen)\n",
        "vgg_test_pred = np.argmax(vgg_test_probs, axis=1)\n",
        "\n",
        "# Create and save VGG-ensemble submission file\n",
        "submission_vgg = pd.DataFrame({\n",
        "    \"id\": test_df[\"id\"],\n",
        "    \"label\": vgg_test_pred\n",
        "})\n",
        "submission_vgg_path = \"submission_vgg_ensemble.csv\"\n",
        "submission_vgg.to_csv(submission_vgg_path, index=False)\n",
        "print(f\"Saved VGG-ensemble submission to {submission_vgg_path}\")\n",
        "print(submission_vgg.head())\n",
        "\n",
        "\n",
        "# --- ViT + VGG ensemble: validate + test ---\n",
        "print(\"\\n=== ViT + VGG ensemble on val + test ===\")\n",
        "\n",
        "# Average probabilities from ViT and VGG ensembles for validation\n",
        "vit_vgg_val_probs = (vit_val_probs + vgg_val_probs) / 2.0\n",
        "vit_vgg_val_pred = np.argmax(vit_vgg_val_probs, axis=1)\n",
        "vit_vgg_val_f1 = f1_score(y_val_true, vit_vgg_val_pred, average=\"macro\")\n",
        "print(f\"ViT + VGG Ensemble Validation F1 (macro): {vit_vgg_val_f1:.4f}\")\n",
        "\n",
        "# Average probabilities from ViT and VGG ensembles for test set\n",
        "vit_vgg_test_probs = (vit_test_probs + vgg_test_probs) / 2.0\n",
        "vit_vgg_test_pred = np.argmax(vit_vgg_test_probs, axis=1)\n",
        "\n",
        "# Create and save combined ViT+VGG ensemble submission file\n",
        "submission_vit_vgg = pd.DataFrame({\n",
        "    \"id\": test_df[\"id\"],\n",
        "    \"label\": vit_vgg_test_pred\n",
        "})\n",
        "submission_vit_vgg_path = \"submission_vit_vgg_ensemble.csv\"\n",
        "submission_vit_vgg.to_csv(submission_vit_vgg_path, index=False)\n",
        "print(f\"Saved ViT+VGG ensemble submission to {submission_vit_vgg_path}\")\n",
        "print(submission_vit_vgg.head())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e3b579b8"
      },
      "source": [
        "# Step 8: Alternative ViT Training Path (Single Model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 383
        },
        "id": "fwoVPUpgZMuC",
        "outputId": "25d290a5-d154-493a-f10b-4c5aa0088c87"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import random\n",
        "import cv2\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import tensorflow as tf\n",
        "import keras\n",
        "from keras import layers, models\n",
        "import keras_hub\n",
        "import keras_cv\n",
        "\n",
        "from sklearn.metrics import f1_score\n",
        "import albumentations as A\n",
        "\n",
        "# Print versions for environment tracking\n",
        "print(\"TF version:\", tf.__version__)\n",
        "print(\"Keras version:\", keras.__version__)\n",
        "print(\"Using backend:\", keras.config.backend())\n",
        "\n",
        "# Define the base path for the dataset\n",
        "dataset_base_path = '/content/cpe342-karena/public_dataset/task4'\n",
        "\n",
        "# --- Reproducibility ---\n",
        "SEED = 42\n",
        "random.seed(SEED)\n",
        "np.random.seed(SEED)\n",
        "tf.random.set_seed(SEED)\n",
        "\n",
        "# --- Albumentations Sequence for data loading and augmentation ---\n",
        "class AlbumentationsSequence(keras.utils.Sequence):\n",
        "    def __init__(self, dataframe, image_dir, batch_size, transform, shuffle=True, is_test=False):\n",
        "        self.df = dataframe.reset_index(drop=True)\n",
        "        self.image_dir = image_dir\n",
        "        self.batch_size = batch_size\n",
        "        self.transform = transform\n",
        "        self.shuffle = shuffle\n",
        "        self.is_test = is_test\n",
        "        self.indices = np.arange(len(self.df))\n",
        "        self.on_epoch_end()\n",
        "\n",
        "    def __len__(self):\n",
        "        return int(np.ceil(len(self.df) / self.batch_size))\n",
        "\n",
        "    def on_epoch_end(self):\n",
        "        if self.shuffle:\n",
        "            np.random.shuffle(self.indices)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        # Get indices for the current batch\n",
        "        batch_indices = self.indices[idx * self.batch_size:(idx + 1) * self.batch_size]\n",
        "        batch_images = []\n",
        "        batch_labels = []\n",
        "\n",
        "        for i in batch_indices:\n",
        "            row = self.df.iloc[i]\n",
        "            file_name = row[\"file_name\"]\n",
        "\n",
        "            # Construct image path and load image\n",
        "            img_path = os.path.join(self.image_dir, file_name)\n",
        "            img = cv2.imread(img_path)\n",
        "            img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "            # Apply transformations if provided\n",
        "            if self.transform is not None:\n",
        "                augmented = self.transform(image=img)\n",
        "                img = augmented[\"image\"]  # Should be float32 [0,1] after ToFloat\n",
        "\n",
        "            batch_images.append(img)\n",
        "            if not self.is_test:\n",
        "                label = int(row[\"label\"])\n",
        "                batch_labels.append(label)\n",
        "\n",
        "        # Convert lists to numpy arrays\n",
        "        batch_x = np.stack(batch_images, axis=0).astype(\"float32\")\n",
        "\n",
        "        if self.is_test:\n",
        "            return batch_x\n",
        "        else:\n",
        "            batch_y = np.array(batch_labels, dtype=\"int32\")\n",
        "            return batch_x, batch_y\n",
        "\n",
        "# --- Transforms for data augmentation and normalization ---\n",
        "train_transform = A.Compose([\n",
        "    A.Resize(224, 224),\n",
        "    A.HorizontalFlip(p=0.5),\n",
        "    A.RandomBrightnessContrast(p=0.5),\n",
        "    A.Affine(\n",
        "        scale=(1 - 0.1, 1 + 0.1),\n",
        "        translate_percent=(0.05, 0.05),\n",
        "        rotate=(-15, 15),\n",
        "        p=0.5\n",
        "    ),\n",
        "    A.GaussNoise(p=0.3),\n",
        "    A.ToFloat(max_value=255.0),  # Normalize to float32 in [0,1]\n",
        "])\n",
        "\n",
        "val_transform = A.Compose([\n",
        "    A.Resize(224, 224),\n",
        "    A.ToFloat(max_value=255.0),  # Normalize to float32 in [0,1]\n",
        "])\n",
        "\n",
        "# --- Load dataframes ---\n",
        "# Reload the dataframes for consistency within this cell\n",
        "try:\n",
        "    train_df = pd.read_csv(f'{dataset_base_path}/train.csv')\n",
        "    val_df = pd.read_csv(f'{dataset_base_path}/val.csv')\n",
        "    test_df = pd.read_csv(f'{dataset_base_path}/test_refined.csv') # Using refined test_refined.csv\n",
        "    print(\"DataFrames reloaded successfully for VIT training.\")\n",
        "except FileNotFoundError as e:\n",
        "    print(f\"Error loading dataframes: {e}. Please ensure the dataset is unzipped and available.\")\n",
        "    raise  # Stop execution if essential files are missing\n",
        "\n",
        "# Define image directories\n",
        "train_image_dir = f'{dataset_base_path}/train'\n",
        "val_image_dir = f'{dataset_base_path}/val'\n",
        "test_image_dir = f'{dataset_base_path}/test'\n",
        "\n",
        "# --- Global constants ---\n",
        "BATCH_SIZE = 8 # Reduced batch size to mitigate OOM for ViT training\n",
        "NUM_CLASSES = 5\n",
        "EPOCHS_VIT = 8\n",
        "\n",
        "# Calculate class weights on full training data\n",
        "counts = train_df[\"label\"].value_counts().sort_index().values.astype(\"float32\")\n",
        "total = counts.sum()\n",
        "class_weights_array = total / (NUM_CLASSES * counts)\n",
        "CLASS_WEIGHT = {i: float(w) for i, w in enumerate(class_weights_array)}\n",
        "print(\"Class weights:\", CLASS_WEIGHT)\n",
        "\n",
        "# --- Build ViT model function ---\n",
        "def build_vit_model(num_classes, input_shape=(224, 224, 3)):\n",
        "    \"\"\"\n",
        "    ViT-Base model from KerasHub, with backbone frozen for initial training.\n",
        "    \"\"\"\n",
        "    print(\"Building ViT-base model (KerasHub)...\")\n",
        "\n",
        "    # Load pretrained ViT backbone from KerasHub (ImageNet pretraining)\n",
        "    backbone = keras_hub.models.ViTBackbone.from_preset(\n",
        "        \"vit_base_patch16_224_imagenet\"\n",
        "    )\n",
        "    backbone.trainable = False  # Freeze backbone to train only the new head initially\n",
        "\n",
        "    inputs = keras.Input(shape=input_shape)\n",
        "    x = inputs\n",
        "    x = backbone(x)          # Pass inputs through the backbone\n",
        "    cls_token = x[:, 0]      # Extract the [CLS] token as the global representation\n",
        "    x = layers.Dropout(0.3)(cls_token) # Add a dropout layer\n",
        "    outputs = layers.Dense(num_classes, activation=\"softmax\")(x) # Output Dense layer\n",
        "\n",
        "    model = keras.Model(inputs, outputs, name=\"vit_base_classifier\")\n",
        "\n",
        "    # Compile the model\n",
        "    model.compile(\n",
        "        optimizer=keras.optimizers.Adam(learning_rate=3e-4),\n",
        "        loss=\"sparse_categorical_crossentropy\",\n",
        "        metrics=[\"accuracy\"],\n",
        "    )\n",
        "    return model\n",
        "\n",
        "# --- Generators for train / val / test datasets ---\n",
        "train_gen = AlbumentationsSequence(\n",
        "    train_df, train_image_dir,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    transform=train_transform,\n",
        "    shuffle=True,\n",
        "    is_test=False\n",
        ")\n",
        "\n",
        "val_gen = AlbumentationsSequence(\n",
        "    val_df, val_image_dir,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    transform=val_transform,\n",
        "    shuffle=False,\n",
        "    is_test=False\n",
        ")\n",
        "\n",
        "test_gen = AlbumentationsSequence(\n",
        "    test_df, test_image_dir,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    transform=val_transform,\n",
        "    shuffle=False,\n",
        "    is_test=True\n",
        ")\n",
        "\n",
        "y_val_true = val_df[\"label\"].values\n",
        "\n",
        "# --- Train ViT (Initial Head Training - Backbone Frozen) ---\n",
        "vit_model = build_vit_model(NUM_CLASSES)\n",
        "\n",
        "vit_ckpt_path = \"vit_finetuned_best.keras\" # Checkpoint path for the best model\n",
        "vit_ckpt_cb = keras.callbacks.ModelCheckpoint(\n",
        "    filepath=vit_ckpt_path,\n",
        "    monitor=\"val_loss\",\n",
        "    mode=\"min\",\n",
        "    save_best_only=True,\n",
        "    save_weights_only=False,\n",
        "    verbose=1,\n",
        ")\n",
        "\n",
        "print(\"\\n=== Training ViT (Head Training with Frozen Backbone) ===\")\n",
        "vit_history = vit_model.fit(\n",
        "    train_gen,\n",
        "    validation_data=val_gen,\n",
        "    epochs=EPOCHS_VIT,\n",
        "    class_weight=CLASS_WEIGHT,\n",
        "    callbacks=[vit_ckpt_cb],\n",
        "    verbose=1,\n",
        ")\n",
        "\n",
        "# Load the best model saved during initial training\n",
        "vit_best = keras.models.load_model(vit_ckpt_path)\n",
        "print(\"Loaded best ViT model from\", vit_ckpt_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "80898d44"
      },
      "source": [
        "## Fine-tuning the Single ViT Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 383
        },
        "id": "uj5KTG7RZYST",
        "outputId": "6076ad7c-e5f2-49c8-9688-071852728f33"
      },
      "outputs": [],
      "source": [
        "from tensorflow import keras\n",
        "import os\n",
        "import random\n",
        "import cv2\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import tensorflow as tf\n",
        "import keras\n",
        "from keras import layers, models\n",
        "import keras_hub\n",
        "import keras_cv\n",
        "\n",
        "from sklearn.metrics import f1_score\n",
        "import albumentations as A\n",
        "\n",
        "# Print versions for environment tracking\n",
        "print(\"TF version:\", tf.__version__)\n",
        "print(\"Keras version:\", keras.__version__)\n",
        "print(\"Using backend:\", keras.config.backend())\n",
        "\n",
        "# Define the base path for the dataset\n",
        "dataset_base_path = '/content/cpe342-karena/public_dataset/task4'\n",
        "\n",
        "# --- Reproducibility ---\n",
        "SEED = 42\n",
        "random.seed(SEED)\n",
        "np.random.seed(SEED)\n",
        "tf.random.set_seed(SEED)\n",
        "\n",
        "# --- Albumentations Sequence for data loading and augmentation ---\n",
        "class AlbumentationsSequence(keras.utils.Sequence):\n",
        "    def __init__(self, dataframe, image_dir, batch_size, transform, shuffle=True, is_test=False):\n",
        "        self.df = dataframe.reset_index(drop=True)\n",
        "        self.image_dir = image_dir\n",
        "        self.batch_size = batch_size\n",
        "        self.transform = transform\n",
        "        self.shuffle = shuffle\n",
        "        self.is_test = is_test\n",
        "        self.indices = np.arange(len(self.df))\n",
        "        self.on_epoch_end()\n",
        "\n",
        "    def __len__(self):\n",
        "        return int(np.ceil(len(self.df) / self.batch_size))\n",
        "\n",
        "    def on_epoch_end(self):\n",
        "        if self.shuffle:\n",
        "            np.random.shuffle(self.indices)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        # Get indices for the current batch\n",
        "        batch_indices = self.indices[idx * self.batch_size:(idx + 1) * self.batch_size]\n",
        "        batch_images = []\n",
        "        batch_labels = []\n",
        "\n",
        "        for i in batch_indices:\n",
        "            row = self.df.iloc[i]\n",
        "            file_name = row[\"file_name\"]\n",
        "\n",
        "            # Construct image path and load image\n",
        "            img_path = os.path.join(self.image_dir, file_name)\n",
        "            img = cv2.imread(img_path)\n",
        "            img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "            # Apply transformations if provided\n",
        "            if self.transform is not None:\n",
        "                augmented = self.transform(image=img)\n",
        "                img = augmented[\"image\"]  # Should be float32 [0,1] after ToFloat\n",
        "\n",
        "            batch_images.append(img)\n",
        "            if not self.is_test:\n",
        "                label = int(row[\"label\"])\n",
        "                batch_labels.append(label)\n",
        "\n",
        "        # Convert lists to numpy arrays\n",
        "        batch_x = np.stack(batch_images, axis=0).astype(\"float32\")\n",
        "\n",
        "        if self.is_test:\n",
        "            return batch_x\n",
        "        else:\n",
        "            batch_y = np.array(batch_labels, dtype=\"int32\")\n",
        "            return batch_x, batch_y\n",
        "\n",
        "# --- Transforms for data augmentation and normalization ---\n",
        "train_transform = A.Compose([\n",
        "    A.Resize(224, 224),\n",
        "    A.HorizontalFlip(p=0.5),\n",
        "    A.RandomBrightnessContrast(p=0.5),\n",
        "    A.Affine(\n",
        "        scale=(1 - 0.1, 1 + 0.1),\n",
        "        translate_percent=(0.05, 0.05),\n",
        "        rotate=(-15, 15),\n",
        "        p=0.5\n",
        "    ),\n",
        "    A.GaussNoise(p=0.3),\n",
        "    A.ToFloat(max_value=255.0),  # Normalize to float32 in [0,1]\n",
        "])\n",
        "\n",
        "val_transform = A.Compose([\n",
        "    A.Resize(224, 224),\n",
        "    A.ToFloat(max_value=255.0),  # Normalize to float32 in [0,1]\n",
        "])\n",
        "\n",
        "# --- Load dataframes ---\n",
        "# Reload the dataframes for consistency within this cell\n",
        "try:\n",
        "    train_df = pd.read_csv(f'{dataset_base_path}/train.csv')\n",
        "    val_df = pd.read_csv(f'{dataset_base_path}/val.csv')\n",
        "    test_df = pd.read_csv(f'{dataset_base_path}/test_refined.csv') # Using refined test_refined.csv\n",
        "    print(\"DataFrames reloaded successfully for VIT training.\")\n",
        "except FileNotFoundError as e:\n",
        "    print(f\"Error loading dataframes: {e}. Please ensure the dataset is unzipped and available.\")\n",
        "    raise  # Stop execution if essential files are missing\n",
        "\n",
        "# Define image directories\n",
        "train_image_dir = f'{dataset_base_path}/train'\n",
        "val_image_dir = f'{dataset_base_path}/val'\n",
        "test_image_dir = f'{dataset_base_path}/test'\n",
        "\n",
        "# --- Global constants ---\n",
        "BATCH_SIZE = 8 # Reduced batch size to mitigate OOM for ViT training\n",
        "NUM_CLASSES = 5\n",
        "EPOCHS_VIT = 8 # (Not directly used in this phase 2 fine-tuning, but kept for context)\n",
        "\n",
        "# Class weights on full training data\n",
        "counts = train_df[\"label\"].value_counts().sort_index().values.astype(\"float32\")\n",
        "total = counts.sum()\n",
        "class_weights_array = total / (NUM_CLASSES * counts)\n",
        "CLASS_WEIGHT = {i: float(w) for i, w in enumerate(class_weights_array)}\n",
        "print(\"Class weights:\", CLASS_WEIGHT)\n",
        "\n",
        "# --- Build ViT model function (re-definition for consistency, though not strictly building from scratch here) ---\n",
        "def build_vit_model(num_classes, input_shape=(224, 224, 3)):\n",
        "    \"\"\"\n",
        "    ViT-Base model from KerasHub. (This function is defined but the model\n",
        "    is loaded from checkpoint for fine-tuning in this cell).\n",
        "    \"\"\"\n",
        "    print(\"Building ViT-base model (KerasHub)...\")\n",
        "\n",
        "    # Load pretrained ViT backbone from KerasHub (ImageNet pretraining)\n",
        "    backbone = keras_hub.models.ViTBackbone.from_preset(\n",
        "        \"vit_base_patch16_224_imagenet\"\n",
        "    )\n",
        "    backbone.trainable = False  # Keep frozen for initial head training, then unfreeze for fine-tuning\n",
        "\n",
        "    inputs = keras.Input(shape=input_shape)\n",
        "    x = inputs\n",
        "    x = backbone(x)          # Pass inputs through the backbone\n",
        "    cls_token = x[:, 0]      # Extract the [CLS] token as the global representation\n",
        "    x = layers.Dropout(0.3)(cls_token) # Add a dropout layer\n",
        "    outputs = layers.Dense(num_classes, activation=\"softmax\")(x) # Output Dense layer\n",
        "\n",
        "    model = keras.Model(inputs, outputs, name=\"vit_base_classifier\")\n",
        "\n",
        "    # Compile the model\n",
        "    model.compile(\n",
        "        optimizer=keras.optimizers.Adam(learning_rate=3e-4),\n",
        "        loss=\"sparse_categorical_crossentropy\",\n",
        "        metrics=[\"accuracy\"],\n",
        "    )\n",
        "    return model\n",
        "\n",
        "# --- Generators for train / val / test datasets ---\n",
        "train_gen = AlbumentationsSequence(\n",
        "    train_df, train_image_dir,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    transform=train_transform,\n",
        "    shuffle=True,\n",
        "    is_test=False\n",
        ")\n",
        "\n",
        "val_gen = AlbumentationsSequence(\n",
        "    val_df, val_image_dir,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    transform=val_transform,\n",
        "    shuffle=False,\n",
        "    is_test=False\n",
        ")\n",
        "\n",
        "test_gen = AlbumentationsSequence(\n",
        "    test_df, test_image_dir,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    transform=val_transform,\n",
        "    shuffle=False,\n",
        "    is_test=True\n",
        ")\n",
        "\n",
        "y_val_true = val_df[\"label\"].values\n",
        "\n",
        "# --- Phase 2: Fine-tuning ViT Backbone ---\n",
        "\n",
        "# 0) Path from previous normal training (Phase 1: head training)\n",
        "vit_ckpt_path = \"vit_initial_best.keras\"  # Ensure this path is correct\n",
        "\n",
        "# 1) Load the previously trained model (with frozen backbone)\n",
        "vit_model = keras.models.load_model(vit_ckpt_path)\n",
        "print(\"Loaded pre-trained ViT from\", vit_ckpt_path)\n",
        "\n",
        "# 2) Grab the backbone (ViTBackbone) layer and unfreeze it\n",
        "# In our build, Input = layer 0, ViTBackbone = layer 1\n",
        "vit_backbone = vit_model.layers[1]\n",
        "vit_backbone.trainable = True # Now the backbone's weights can be updated\n",
        "\n",
        "# 3) Recompile the entire model with a very small learning rate for fine-tuning\n",
        "vit_model.compile(\n",
        "    optimizer=keras.optimizers.Adam(learning_rate=1e-5), # Use a significantly smaller LR\n",
        "    loss=\"sparse_categorical_crossentropy\",\n",
        "    metrics=[\"accuracy\"],\n",
        ")\n",
        "\n",
        "# 4) New checkpoint for this fine-tuned phase\n",
        "vit_ft_ckpt_path = \"vit_finetuned_best.keras\"\n",
        "vit_ft_ckpt_cb = keras.callbacks.ModelCheckpoint(\n",
        "    filepath=vit_ft_ckpt_path,\n",
        "    monitor=\"val_loss\",\n",
        "    mode=\"min\",\n",
        "    save_best_only=True,\n",
        "    save_weights_only=False,\n",
        "    verbose=1,\n",
        ")\n",
        "\n",
        "print(\"\\n=== Phase 2: Fine-tuning ViT Backbone from saved checkpoint ===\")\n",
        "vit_ft_history = vit_model.fit(\n",
        "    train_gen,\n",
        "    validation_data=val_gen,\n",
        "    epochs=5,            # Adjust number of epochs for fine-tuning\n",
        "    class_weight=CLASS_WEIGHT,\n",
        "    callbacks=[vit_ft_ckpt_cb],\n",
        "    verbose=1,\n",
        ")\n",
        "\n",
        "# 5) Load the best model from this fine-tuning phase\n",
        "vit_best = keras.models.load_model(vit_ft_ckpt_path)\n",
        "print(\"Loaded fine-tuned ViT model from\", vit_ft_ckpt_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a3cb8091"
      },
      "source": [
        "# Final Model Evaluation and Submission"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zBYiWroqqgNK"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import f1_score\n",
        "import numpy as np\n",
        "from tensorflow import keras\n",
        "\n",
        "# -----------------------------------------\n",
        "# 1) ViT alone: validate + test submission\n",
        "# -----------------------------------------\n",
        "\n",
        "print(\"\\n=== ViT: evaluation on val + prediction on test ===\")\n",
        "\n",
        "# ViT on validation\n",
        "vit_val_probs = vit_best.predict(val_gen, verbose=0)\n",
        "vit_val_pred = np.argmax(vit_val_probs, axis=1)\n",
        "vit_val_f1 = f1_score(y_val_true, vit_val_pred, average=\"macro\")\n",
        "print(f\"ViT Validation F1 (macro): {vit_val_f1:.4f}\")\n",
        "\n",
        "# ViT on test (no labels, just predictions)\n",
        "vit_test_probs = vit_best.predict(test_gen, verbose=0)\n",
        "vit_test_pred = np.argmax(vit_test_probs, axis=1)\n",
        "\n",
        "submission_vit = pd.DataFrame({\n",
        "    \"id\": test_df[\"id\"],\n",
        "    \"label\": vit_test_pred\n",
        "})\n",
        "submission_vit_path = \"submission_vit_only.csv\"\n",
        "submission_vit.to_csv(submission_vit_path, index=False)\n",
        "print(f\"Saved ViT-only submission to {submission_vit_path}\")\n",
        "print(submission_vit.head())\n",
        "\n",
        "\n",
        "# -----------------------------------------\n",
        "# 2) VGG ensemble: validate + test\n",
        "# -----------------------------------------\n",
        "\n",
        "print(\"\\n=== VGG (CV models) ensemble on val + test ===\")\n",
        "\n",
        "# Adjust these paths if filenames are different\n",
        "vgg_paths = [\n",
        "    \"vgg16_fine_tuned_best.keras\"\n",
        "]\n",
        "\n",
        "def predict_ensemble(paths, generator):\n",
        "    all_probs = None\n",
        "    num_used = 0\n",
        "\n",
        "    for path in paths:\n",
        "        try:\n",
        "            model = keras.models.load_model(path)\n",
        "        except Exception as e:\n",
        "            print(f\"Could not load {path}: {e}\")\n",
        "            continue\n",
        "\n",
        "        probs = model.predict(generator, verbose=0)\n",
        "        if all_probs is None:\n",
        "            all_probs = probs\n",
        "        else:\n",
        "            all_probs += probs\n",
        "\n",
        "        num_used += 1\n",
        "\n",
        "    if num_used == 0:\n",
        "        raise ValueError(\"No models successfully loaded for ensemble.\")\n",
        "\n",
        "    all_probs /= num_used\n",
        "    return all_probs\n",
        "\n",
        "# VGG ensemble on val\n",
        "vgg_val_probs = predict_ensemble(vgg_paths, val_gen)\n",
        "vgg_val_pred = np.argmax(vgg_val_probs, axis=1)\n",
        "vgg_val_f1 = f1_score(y_val_true, vgg_val_pred, average=\"macro\")\n",
        "print(f\"VGG CV Ensemble Validation F1 (macro): {vgg_val_f1:.4f}\")\n",
        "\n",
        "# VGG ensemble on test\n",
        "vgg_test_probs = predict_ensemble(vgg_paths, test_gen)\n",
        "vgg_test_pred = np.argmax(vgg_test_probs, axis=1)\n",
        "\n",
        "submission_vgg = pd.DataFrame({\n",
        "    \"id\": test_df[\"id\"],\n",
        "    \"label\": vgg_test_pred\n",
        "})\n",
        "submission_vgg_path = \"submission_vgg_ensemble.csv\"\n",
        "submission_vgg.to_csv(submission_vgg_path, index=False)\n",
        "print(f\"Saved VGG-ensemble submission to {submission_vgg_path}\")\n",
        "print(submission_vgg.head())\n",
        "\n",
        "\n",
        "# -----------------------------------------\n",
        "# 3) ViT + VGG ensemble: validate + test\n",
        "# -----------------------------------------\n",
        "\n",
        "print(\"\\n=== ViT + VGG ensemble on val + test ===\")\n",
        "\n",
        "# Ensemble probabilities on validation\n",
        "vit_vgg_val_probs = (vit_val_probs + vgg_val_probs) / 2.0\n",
        "vit_vgg_val_pred = np.argmax(vit_vgg_val_probs, axis=1)\n",
        "vit_vgg_val_f1 = f1_score(y_val_true, vit_vgg_val_pred, average=\"macro\")\n",
        "print(f\"ViT + VGG Ensemble Validation F1 (macro): {vit_vgg_val_f1:.4f}\")\n",
        "\n",
        "# Ensemble probabilities on test\n",
        "vit_vgg_test_probs = (vit_test_probs + vgg_test_probs) / 2.0\n",
        "vit_vgg_test_pred = np.argmax(vit_vgg_test_probs, axis=1)\n",
        "\n",
        "submission_vit_vgg = pd.DataFrame({\n",
        "    \"id\": test_df[\"id\"],\n",
        "    \"label\": vit_vgg_test_pred\n",
        "})\n",
        "submission_vit_vgg_path = \"submission_vit_vgg_ensemble.csv\"\n",
        "submission_vit_vgg.to_csv(submission_vit_vgg_path, index=False)\n",
        "print(f\"Saved ViT+VGG ensemble submission to {submission_vit_vgg_path}\")\n",
        "print(submission_vit_vgg.head())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7a89c1f8"
      },
      "source": [
        "# Step 9: Model Evaluation on Validation Set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I46sULOuOGDa",
        "outputId": "1d8b94dc-4f7a-430d-d053-59320389d426"
      },
      "outputs": [],
      "source": [
        "    from google.colab import drive\n",
        "    drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gj1nWzsJONq0",
        "outputId": "e8463ac9-db9a-46f1-9f84-7c06febdb3c2"
      },
      "outputs": [],
      "source": [
        "    %cd /content/drive/My Drive/loadedModel/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "92b53b64",
        "outputId": "0c717cd7-82ed-4428-8a01-a13e6b2af85c"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import cv2\n",
        "import os\n",
        "import albumentations as A\n",
        "from sklearn.metrics import f1_score, classification_report\n",
        "from sklearn.model_selection import StratifiedKFold # Needed for fold_splits definition\n",
        "import keras_hub # For ViT models\n",
        "import keras_cv # For build_swin_model if any .keras depends on it (safer to include)\n",
        "from tensorflow import keras # Alias for tf.keras\n",
        "\n",
        "# Define the base path for the dataset\n",
        "dataset_base_path = '/content/cpe342-karena/public_dataset/task4'\n",
        "\n",
        "# --- Albumentations Sequence for data loading ---\n",
        "class AlbumentationsSequence(tf.keras.utils.Sequence):\n",
        "    def __init__(self, dataframe, image_dir, batch_size, transform, shuffle=True, is_test=False):\n",
        "        self.df = dataframe.reset_index(drop=True)\n",
        "        self.image_dir = image_dir\n",
        "        self.batch_size = batch_size\n",
        "        self.transform = transform\n",
        "        self.shuffle = shuffle\n",
        "        self.is_test = is_test\n",
        "        self.indices = np.arange(len(self.df))\n",
        "        self.on_epoch_end()\n",
        "\n",
        "    def __len__(self):\n",
        "        return int(np.ceil(len(self.df) / self.batch_size))\n",
        "\n",
        "    def on_epoch_end(self):\n",
        "        if self.shuffle:\n",
        "            np.random.shuffle(self.indices)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        batch_indices = self.indices[idx * self.batch_size:(idx + 1) * self.batch_size]\n",
        "        batch_images = []\n",
        "        batch_labels = []\n",
        "\n",
        "        for i in batch_indices:\n",
        "            row = self.df.iloc[i]\n",
        "            file_name = row[\"file_name\"]\n",
        "            img_path = os.path.join(self.image_dir, file_name)\n",
        "            img = cv2.imread(img_path)\n",
        "            img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "            if self.transform:\n",
        "                augmented = self.transform(image=img)\n",
        "                img = augmented[\"image\"]\n",
        "\n",
        "            batch_images.append(img)\n",
        "            if not self.is_test:\n",
        "                label = int(row[\"label\"])\n",
        "                batch_labels.append(label)\n",
        "\n",
        "        batch_x = np.stack(batch_images, axis=0).astype(\"float32\")\n",
        "\n",
        "        if self.is_test:\n",
        "            return batch_x\n",
        "        else:\n",
        "            batch_y = np.array(batch_labels, dtype=\"int32\")\n",
        "            return batch_x, batch_y\n",
        "\n",
        "# --- Image transformations (consistent with previous cells) ---\n",
        "imagenet_mean = (0.485, 0.456, 0.406)\n",
        "imagenet_std  = (0.229, 0.224, 0.225)\n",
        "\n",
        "# For VGG16 models\n",
        "vgg_val_transform = A.Compose([\n",
        "    A.Resize(224, 224),\n",
        "    A.Normalize(mean=imagenet_mean, std=imagenet_std),\n",
        "])\n",
        "\n",
        "# For ViT models (assuming they expect [0,1] range as per their definition)\n",
        "vit_val_transform = A.Compose([\n",
        "    A.Resize(224, 224),\n",
        "    A.ToFloat(max_value=255.0),\n",
        "])\n",
        "\n",
        "# --- Load dataframes ---\n",
        "try:\n",
        "    train_df = pd.read_csv(f'{dataset_base_path}/train.csv')\n",
        "    val_df = pd.read_csv(f'{dataset_base_path}/val.csv')\n",
        "    test_df = pd.read_csv(f'{dataset_base_path}/test_refined.csv')\n",
        "    print(\"DataFrames loaded successfully.\")\n",
        "except FileNotFoundError as e:\n",
        "    print(f\"Error loading dataframes: {e}. Please ensure the dataset is unzipped and available.\")\n",
        "    raise\n",
        "\n",
        "# Define image directories\n",
        "train_image_dir = f'{dataset_base_path}/train'\n",
        "val_image_dir = f'{dataset_base_path}/val'\n",
        "test_image_dir = f'{dataset_base_path}/test'\n",
        "\n",
        "# --- Global Constants ---\n",
        "BATCH_SIZE = 32 # Can be adjusted for ViT evaluation if needed, but 32 is common.\n",
        "NUM_CLASSES = 5\n",
        "\n",
        "# --- Setup Main Validation Data Generator and True Labels ---\n",
        "# Using val_df from the overall dataset for consistent evaluation across all models\n",
        "main_val_gen_vgg = AlbumentationsSequence(\n",
        "    val_df,\n",
        "    val_image_dir,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    transform=vgg_val_transform,\n",
        "    shuffle=False\n",
        ")\n",
        "main_val_gen_vit = AlbumentationsSequence(\n",
        "    val_df,\n",
        "    val_image_dir,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    transform=vit_val_transform,\n",
        "    shuffle=False\n",
        ")\n",
        "main_y_true = val_df['label'].values\n",
        "print(\"Main validation data generators (VGG-compatible and ViT-compatible) and true labels prepared.\")\n",
        "\n",
        "# --- Define evaluation function for single models ---\n",
        "def evaluate_single_model(model_path, data_generator, true_labels, model_name=\"Model\"):\n",
        "    print(f\"\\n--- Evaluating {model_name} ({model_path}) ---\")\n",
        "    try:\n",
        "        model = tf.keras.models.load_model(model_path)\n",
        "\n",
        "        loss, accuracy = model.evaluate(data_generator, verbose=0)\n",
        "        print(f\"{model_name} Loss: {loss:.4f}, Accuracy: {accuracy:.4f}\")\n",
        "\n",
        "        predictions_probs = model.predict(data_generator, verbose=0)\n",
        "        predictions = np.argmax(predictions_probs, axis=1)\n",
        "\n",
        "        f1_macro = f1_score(true_labels, predictions, average='macro', zero_division=0)\n",
        "        print(f\"{model_name} F1-Macro: {f1_macro:.4f}\")\n",
        "\n",
        "        print(f\"\\n{model_name} Classification Report:\")\n",
        "        print(classification_report(true_labels, predictions, zero_division=0))\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error evaluating {model_name} from {model_path}: {e}\")\n",
        "\n",
        "# --- Define ensemble prediction function ---\n",
        "def ensemble_predict(model_paths, generator, model_type='vgg'):\n",
        "    all_probs = None\n",
        "    loaded_models = []\n",
        "    print(f\"Loading {len(model_paths)} models for ensembling (type: {model_type})...\")\n",
        "\n",
        "    # Determine which transform to use for the generator based on model_type\n",
        "    current_generator = None\n",
        "    if model_type == 'vgg':\n",
        "        current_generator = AlbumentationsSequence(generator.df, generator.image_dir, generator.batch_size, vgg_val_transform, shuffle=False)\n",
        "    elif model_type == 'vit':\n",
        "        current_generator = AlbumentationsSequence(generator.df, generator.image_dir, generator.batch_size, vit_val_transform, shuffle=False)\n",
        "    else: # For combined ensemble where individual model types might be mixed\n",
        "        current_generator = generator # Assume generator is already correctly transformed\n",
        "\n",
        "    for path in model_paths:\n",
        "        try:\n",
        "            m = tf.keras.models.load_model(path)\n",
        "            loaded_models.append(m)\n",
        "            print(f\"Loaded model: {path}\")\n",
        "        except Exception as e:\n",
        "            print(f\"Error loading model {path}: {e}. Skipping this model.\")\n",
        "\n",
        "    if not loaded_models:\n",
        "        raise ValueError(\"No models were successfully loaded for ensembling.\")\n",
        "\n",
        "    print(f\"Making predictions with {len(loaded_models)} loaded models...\")\n",
        "    for i, m in enumerate(loaded_models):\n",
        "        # Use current_generator for prediction\n",
        "        probs = m.predict(current_generator, verbose=0)\n",
        "        if all_probs is None:\n",
        "            all_probs = probs\n",
        "        else:\n",
        "            all_probs += probs\n",
        "    all_probs /= len(loaded_models)\n",
        "    return all_probs\n",
        "\n",
        "# --- Model Paths ---\n",
        "single_vgg_initial = '/content/drive/My Drive/loadedModel/vgg16_initial_best.keras'\n",
        "single_vgg_finetuned = '/content/drive/My Drive/loadedModel/vgg16_finetuned_best.keras'\n",
        "\n",
        "cv_vgg_finetuned_paths = [\n",
        "    '/content/drive/My Drive/loadedModel/vgg16_cv_fold_1_finetuned_best.keras',\n",
        "    '/content/drive/My Drive/loadedModel/vgg16_cv_fold_2_finetuned_best.keras',\n",
        "    '/content/drive/My Drive/loadedModel/vgg16_cv_fold_3_finetuned_best.keras',\n",
        "]\n",
        "\n",
        "single_vit_initial = '/content/drive/My Drive/loadedModel/vit_initial_best.keras' # Assuming this is from Phase 1 head training\n",
        "single_vit_finetuned = '/content/drive/My Drive/loadedModel/vit_finetuned_best.keras' # Assuming this is from Phase 2 backbone fine-tuning\n",
        "\n",
        "cv_vit_finetuned_paths = [\n",
        "    '/content/drive/My Drive/loadedModel/vit_cv_fold_1_best.keras', # Assuming these are the best from CV folds, potentially already fine-tuned\n",
        "    '/content/drive/My Drive/loadedModel/vit_cv_fold_2_best.keras',\n",
        "    '/content/drive/My Drive/loadedModel/vit_cv_fold_3_best.keras',\n",
        "]\n",
        "\n",
        "# Aggregate all single model paths for iteration\n",
        "model_paths_to_evaluate_single = [\n",
        "    single_vgg_initial,\n",
        "    single_vgg_finetuned,\n",
        "    single_vit_initial,\n",
        "    single_vit_finetuned\n",
        "]\n",
        "\n",
        "# Map friendly names to paths\n",
        "model_names = {\n",
        "    single_vgg_initial: 'VGG16 Initial (Frozen Head)',\n",
        "    single_vgg_finetuned: 'VGG16 Fine-tuned (Single Model)',\n",
        "    single_vit_initial: 'ViT Initial (Single Model - Head Trained)',\n",
        "    single_vit_finetuned: 'ViT Fine-tuned (Single Model - Backbone Trained)',\n",
        "    '/content/drive/My Drive/loadedModel/vgg16_cv_fold_1_finetuned_best.keras': 'VGG16 CV Fold 1 Fine-tuned',\n",
        "    '/content/drive/My Drive/loadedModel/vgg16_cv_fold_2_finetuned_best.keras': 'VGG16 CV Fold 2 Fine-tuned',\n",
        "    '/content/drive/My Drive/loadedModel/vgg16_cv_fold_3_finetuned_best.keras': 'VGG16 CV Fold 3 Fine-tuned',\n",
        "    '/content/drive/My Drive/loadedModel/vit_cv_fold_1_best.keras': 'ViT CV Fold 1',\n",
        "    '/content/drive/My Drive/loadedModel/vit_cv_fold_2_best.keras': 'ViT CV Fold 2',\n",
        "    '/content/drive/My Drive/loadedModel/vit_cv_fold_3_best.keras': 'ViT CV Fold 3',\n",
        "}\n",
        "\n",
        "# --- Evaluate Single Models ---\n",
        "print(\"\\n===== Evaluating Individual Models =====\")\n",
        "for path in model_paths_to_evaluate_single:\n",
        "    name = model_names.get(path, path)\n",
        "    # Use the appropriate generator based on model type\n",
        "    if 'vgg16' in name.lower():\n",
        "        evaluate_single_model(path, main_val_gen_vgg, main_y_true, model_name=name)\n",
        "    elif 'vit' in name.lower():\n",
        "        evaluate_single_model(path, main_val_gen_vit, main_y_true, model_name=name)\n",
        "    else:\n",
        "        print(f\"Warning: Could not determine generator type for {name}. Skipping.\")\n",
        "\n",
        "# --- Evaluate Ensemble Models ---\n",
        "print(\"\\n===== Evaluating Ensemble Models =====\")\n",
        "\n",
        "# VGG16 CV Ensemble\n",
        "if cv_vgg_finetuned_paths:\n",
        "    print(\"\\n--- Evaluating VGG16 CV Ensemble ---\")\n",
        "    try:\n",
        "        vgg_ensemble_probs = ensemble_predict(cv_vgg_finetuned_paths, main_val_gen_vgg, model_type='vgg')\n",
        "        vgg_ensemble_pred = np.argmax(vgg_ensemble_probs, axis=1)\n",
        "        vgg_ensemble_f1 = f1_score(main_y_true, vgg_ensemble_pred, average='macro', zero_division=0)\n",
        "        print(f\"VGG16 CV Ensemble F1-Macro: {vgg_ensemble_f1:.4f}\")\n",
        "        print(\"VGG16 CV Ensemble Classification Report:\")\n",
        "        print(classification_report(main_y_true, vgg_ensemble_pred, zero_division=0))\n",
        "    except Exception as e:\n",
        "        print(f\"Error evaluating VGG16 CV Ensemble: {e}\")\n",
        "else:\n",
        "    print(\"VGG16 CV Ensemble paths not found or empty. Skipping evaluation.\")\n",
        "\n",
        "# ViT CV Ensemble\n",
        "if cv_vit_finetuned_paths:\n",
        "    print(\"\\n--- Evaluating ViT CV Ensemble ---\")\n",
        "    try:\n",
        "        # For ViT ensemble, pass the vit-compatible generator\n",
        "        vit_ensemble_probs = ensemble_predict(cv_vit_finetuned_paths, main_val_gen_vit, model_type='vit')\n",
        "        vit_ensemble_pred = np.argmax(vit_ensemble_probs, axis=1)\n",
        "        vit_ensemble_f1 = f1_score(main_y_true, vit_ensemble_pred, average='macro', zero_division=0)\n",
        "        print(f\"ViT CV Ensemble F1-Macro: {vit_ensemble_f1:.4f}\")\n",
        "        print(\"ViT CV Ensemble Classification Report:\")\n",
        "        print(classification_report(main_y_true, vit_ensemble_pred, zero_division=0))\n",
        "    except Exception as e:\n",
        "        print(f\"Error evaluating ViT CV Ensemble: {e}\")\n",
        "else:\n",
        "    print(\"ViT CV Ensemble paths not found or empty. Skipping evaluation.\")\n",
        "\n",
        "# --- Overall Ensemble (VGG16 CV Fine-tuned + ViT CV Fine-tuned) ---\n",
        "# To combine, we need probabilities from both VGG and ViT models on the SAME validation set.\n",
        "# We assume the VGG models are evaluated with vgg_val_transform and ViT models with vit_val_transform\n",
        "# The final ensemble logic will need both sets of probabilities to be combined AFTER individual model predictions.\n",
        "\n",
        "print(\"\\n--- Evaluating Overall Ensemble (VGG16 CV + ViT CV) ---\")\n",
        "try:\n",
        "    # Get probabilities from VGG ensemble\n",
        "    vgg_combined_probs = None\n",
        "    if cv_vgg_finetuned_paths:\n",
        "        vgg_combined_probs = ensemble_predict(cv_vgg_finetuned_paths, main_val_gen_vgg, model_type='vgg')\n",
        "    else:\n",
        "        print(\"VGG16 CV Ensemble paths missing for combined ensemble.\")\n",
        "\n",
        "    # Get probabilities from ViT ensemble\n",
        "    vit_combined_probs = None\n",
        "    if cv_vit_finetuned_paths:\n",
        "        vit_combined_probs = ensemble_predict(cv_vit_finetuned_paths, main_val_gen_vit, model_type='vit')\n",
        "    else:\n",
        "        print(\"ViT CV Ensemble paths missing for combined ensemble.\")\n",
        "\n",
        "    if vgg_combined_probs is not None and vit_combined_probs is not None:\n",
        "        # Average the probabilities from the two ensembles\n",
        "        overall_ensemble_probs = (vgg_combined_probs + vit_combined_probs) / 2.0\n",
        "        overall_ensemble_pred = np.argmax(overall_ensemble_probs, axis=1)\n",
        "        overall_ensemble_f1 = f1_score(main_y_true, overall_ensemble_pred, average='macro', zero_division=0)\n",
        "        print(f\"Overall Ensemble (VGG16 CV + ViT CV) F1-Macro: {overall_ensemble_f1:.4f}\")\n",
        "        print(\"Overall Ensemble (VGG16 CV + ViT CV) Classification Report:\")\n",
        "        print(classification_report(main_y_true, overall_ensemble_pred, zero_division=0))\n",
        "    else:\n",
        "        print(\"Skipping overall ensemble evaluation due to missing probabilities from sub-ensembles.\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"Error evaluating Overall Ensemble: {e}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"\\n===== Evaluating Ensemble of Single Fine-tuned Models =====\")\n",
        "# --- Model Paths ---\n",
        "single_vgg_finetuned_path = '/content/drive/My Drive/loadedModel/vgg16_fine_tuned_best.keras'\n",
        "single_vit_finetuned_path = '/content/drive/My Drive/loadedModel/vit_finetuned_best.keras'\n",
        "\n",
        "# --- Load Models ---\n",
        "print(\"\\nLoading individual models for ensemble evaluation...\")\n",
        "try:\n",
        "    vgg_model = tf.keras.models.load_model(single_vgg_finetuned_path)\n",
        "    print(f\"Loaded VGG16 Fine-tuned model from {single_vgg_finetuned_path}\")\n",
        "except Exception as e:\n",
        "    print(f\"Error loading VGG16 Fine-tuned model: {e}\")\n",
        "    vgg_model = None\n",
        "\n",
        "try:\n",
        "    vit_model = tf.keras.models.load_model(single_vit_finetuned_path)\n",
        "    print(f\"Loaded ViT Fine-tuned model from {single_vit_finetuned_path}\")\n",
        "except Exception as e:\n",
        "    print(f\"Error loading ViT Fine-tuned model: {e}\")\n",
        "    vit_model = None\n",
        "\n",
        "# --- Generate Predictions and Evaluate Ensemble ---\n",
        "if vgg_model and vit_model:\n",
        "    print(\"\\nGenerating predictions from individual models...\")\n",
        "    vgg_val_probs = vgg_model.predict(main_val_gen_vgg, verbose=0)\n",
        "    vit_val_probs = vit_model.predict(main_val_gen_vit, verbose=0)\n",
        "\n",
        "    # Average probabilities for ensemble\n",
        "    ensemble_val_probs = (vgg_val_probs + vit_val_probs) / 2.0\n",
        "    ensemble_val_pred = np.argmax(ensemble_val_probs, axis=1)\n",
        "\n",
        "    # Calculate ensemble metrics\n",
        "    ensemble_f1_macro = f1_score(main_y_true, ensemble_val_pred, average='macro', zero_division=0)\n",
        "    ensemble_accuracy = np.mean(ensemble_val_pred == main_y_true)\n",
        "\n",
        "    print(\"\\n--- Ensemble (VGG16 Fine-tuned + ViT Fine-tuned) Evaluation on Validation Set ---\")\n",
        "    print(f\"Ensemble Accuracy: {ensemble_accuracy:.4f}\")\n",
        "    print(f\"Ensemble F1-Macro: {ensemble_f1_macro:.4f}\")\n",
        "    print(\"\\nEnsemble Classification Report:\")\n",
        "    print(classification_report(main_y_true, ensemble_val_pred, zero_division=0))\n",
        "else:\n",
        "    print(\"Skipping ensemble evaluation due to missing one or both models.\")\n",
        "\n",
        "print(\"\\nEnsemble evaluation complete.\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
