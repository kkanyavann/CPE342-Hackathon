{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# TASK#3: Player Monthly Spending Prediction\n",
        "\n",
        "Karena Thailand's finance team struggles with revenue forecasting,\n",
        "consistently missing quarterly targets by 35-40%, which impacts budgeting,\n",
        "hiring decisions, and investor confidence. Without accurate player-level\n",
        "spending predictions, multiple departments are operating blindly. The VIP\n",
        "support team of 20 people provides white-glove service but doesn't know\n",
        "which players actually deserve priority treatment‚Äîlast quarter they spent\n",
        "significant resources on 150 high-playtime players who collectively spent\n",
        "only ‡∏ø12,000, while a whale who spent ‡∏ø255,000 waited 3 days for ticket\n",
        "response and subsequently left for a competitor. The marketing team sends\n",
        "promotional discount codes randomly, often giving 50% off to whales who\n",
        "would have paid full price anyway, resulting in ‡∏ø6 million+ monthly revenue\n",
        "loss. Customer service wastes time on players unlikely to ever monetize while\n",
        "high-value customers receive generic treatment. Additionally, the company\n",
        "needs to optimize their limited-time event scheduling and new content\n",
        "releases based on when high-spending players are most active. Accurate\n",
        "spending predictions would enable proper resource allocation, targeted\n",
        "offers, revenue forecasting, and VIP program optimization across the\n",
        "organization.\n"
      ],
      "metadata": {
        "id": "48mLoF42lTkV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# STEP 1: Import and setup"
      ],
      "metadata": {
        "id": "PQprJGlmnKc_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "from lightgbm import early_stopping, log_evaluation"
      ],
      "metadata": {
        "id": "itBpGy6IlZpi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "TRAIN_PATH = \"train.csv\"\n",
        "TEST_PATH = \"test.csv\"\n",
        "OUTPUT_SUB_PATH = \"submission_task3_baseline.csv\"\n",
        "\n",
        "TARGET_COL = \"spending_30d\"   # ‡∏ä‡∏∑‡πà‡∏≠ target ‡πÉ‡∏ô train.csv\n",
        "USE_LOG_TARGET = False\n",
        "\n",
        "\n",
        "def nmae(y_true, y_pred):\n",
        "    \"\"\"Normalized MAE = sum(|y-y_hat|) / sum(|y|)\"\"\"\n",
        "    return np.sum(np.abs(y_true - y_pred)) / np.sum(np.abs(y_true))"
      ],
      "metadata": {
        "id": "J21JH-Twv8yG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# STEP 2: Load data\n"
      ],
      "metadata": {
        "id": "jc2n-8xtoqO3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train = pd.read_csv(TRAIN_PATH)\n",
        "test = pd.read_csv(TEST_PATH)\n",
        "\n",
        "print(\"Train shape:\", train.shape)\n",
        "print(\"Test shape :\", test.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c93sZ37zxUia",
        "outputId": "3e928515-b97d-4be7-ba91-a121188dc025"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train shape: (104000, 35)\n",
            "Test shape : (25889, 34)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# STEP 3: Define feature columns"
      ],
      "metadata": {
        "id": "0Abl3flGove_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "FEATURE_COLS = [\n",
        "    \"friend_count\",\n",
        "    \"social_interactions\",\n",
        "    \"guild_membership\",\n",
        "    \"event_participation_rate\",\n",
        "    \"daily_login_streak\",\n",
        "    \"avg_session_length\",\n",
        "    \"sessions_per_week\",\n",
        "    \"total_playtime_hours\",\n",
        "    \"days_since_last_login\",\n",
        "    \"achievement_count\",\n",
        "    \"achievement_completion_rate\",\n",
        "    \"historical_spending\",\n",
        "    \"prev_month_spending\",\n",
        "    \"total_transactions\",\n",
        "    \"avg_transaction_value\",\n",
        "    \"account_age_days\",\n",
        "    \"vip_status\",\n",
        "    \"is_premium_member\",\n",
        "    \"primary_game\",\n",
        "    \"games_played\",\n",
        "    \"cross_game_activity\",\n",
        "    \"platform\",\n",
        "    \"days_since_last_purchase\",\n",
        "    \"purchase_frequency\",\n",
        "    \"payment_methods_used\",\n",
        "    \"purchases_on_discount\",\n",
        "    \"discount_rate_used\",\n",
        "    \"seasonal_spending_pattern\",\n",
        "    \"owns_limited_edition\",\n",
        "    \"competitive_rank\",\n",
        "    \"tournament_participation\",\n",
        "    \"segment\",\n",
        "]\n",
        "\n",
        "missing_in_train = [c for c in FEATURE_COLS if c not in train.columns]\n",
        "missing_in_test = [c for c in FEATURE_COLS if c not in test.columns]\n",
        "\n",
        "if missing_in_train:\n",
        "    print(\"‚ö†Ô∏è Missing in train:\", missing_in_train)\n",
        "if missing_in_test:\n",
        "    print(\"‚ö†Ô∏è Missing in test:\", missing_in_test)\n",
        "\n",
        "FEATURE_COLS = [\n",
        "    c for c in FEATURE_COLS\n",
        "    if c in train.columns and c in test.columns\n",
        "]\n",
        "print(\"‚úÖ Use features:\", len(FEATURE_COLS))\n",
        "print(FEATURE_COLS)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KHi2xLAFwMCx",
        "outputId": "592a2c79-6c42-41b9-bbc4-6e01f9342fed"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Use features: 32\n",
            "['friend_count', 'social_interactions', 'guild_membership', 'event_participation_rate', 'daily_login_streak', 'avg_session_length', 'sessions_per_week', 'total_playtime_hours', 'days_since_last_login', 'achievement_count', 'achievement_completion_rate', 'historical_spending', 'prev_month_spending', 'total_transactions', 'avg_transaction_value', 'account_age_days', 'vip_status', 'is_premium_member', 'primary_game', 'games_played', 'cross_game_activity', 'platform', 'days_since_last_purchase', 'purchase_frequency', 'payment_methods_used', 'purchases_on_discount', 'discount_rate_used', 'seasonal_spending_pattern', 'owns_limited_edition', 'competitive_rank', 'tournament_participation', 'segment']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# STEP 4: Prepare X, y and handle missing values"
      ],
      "metadata": {
        "id": "h62jh6uYozEp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y = train[TARGET_COL].astype(float)\n",
        "X = train[FEATURE_COLS].astype(float)\n",
        "X_test = test[FEATURE_COLS].astype(float)\n",
        "\n",
        "for col in FEATURE_COLS:\n",
        "    med = X[col].median()\n",
        "    X[col] = X[col].fillna(med)\n",
        "    X_test[col] = X_test[col].fillna(med)"
      ],
      "metadata": {
        "id": "MaqpoplHwQek"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# STEP 5: Feature Engineering"
      ],
      "metadata": {
        "id": "_aTvrwlQo2px"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X[\"spend_per_session\"] = X[\"historical_spending\"] / (X[\"sessions_per_week\"] + 1)\n",
        "X_test[\"spend_per_session\"] = X_test[\"historical_spending\"] / (X_test[\"sessions_per_week\"] + 1)\n",
        "\n",
        "X[\"spend_per_hour\"] = X[\"historical_spending\"] / (X[\"total_playtime_hours\"] + 1)\n",
        "X_test[\"spend_per_hour\"] = X_test[\"historical_spending\"] / (X_test[\"total_playtime_hours\"] + 1)\n",
        "\n",
        "X[\"recency_score\"] = 1 / (X[\"days_since_last_purchase\"] + 1)\n",
        "X_test[\"recency_score\"] = 1 / (X_test[\"days_since_last_purchase\"] + 1)\n",
        "\n",
        "X[\"engagement_score\"] = (\n",
        "    0.3 * X[\"social_interactions\"] +\n",
        "    0.3 * X[\"event_participation_rate\"] +\n",
        "    0.2 * X[\"friend_count\"] +\n",
        "    0.2 * X[\"guild_membership\"]\n",
        ")\n",
        "\n",
        "X_test[\"engagement_score\"] = (\n",
        "    0.3 * X_test[\"social_interactions\"] +\n",
        "    0.3 * X_test[\"event_participation_rate\"] +\n",
        "    0.2 * X_test[\"friend_count\"] +\n",
        "    0.2 * X_test[\"guild_membership\"]\n",
        ")"
      ],
      "metadata": {
        "id": "TlQOeRcRtOgO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# STEP 6: Train/Validation split + Baseline"
      ],
      "metadata": {
        "id": "LMZJOdW1o9JB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_valid, y_train, y_valid = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "print(\"Train size:\", X_train.shape, \"Valid size:\", X_valid.shape)\n",
        "\n",
        "mean_pred = y_train.mean()\n",
        "y_valid_mean = np.full_like(y_valid, mean_pred, dtype=float)\n",
        "baseline_nmae = nmae(y_valid, y_valid_mean)\n",
        "print(f\"Baseline NMAE (mean predictor): {baseline_nmae:.6f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cxc3xIY5xf2i",
        "outputId": "6db73575-94e1-49c4-9853-c2139628ea4a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train size: (83200, 36) Valid size: (20800, 36)\n",
            "Baseline NMAE (mean predictor): 1.603269\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# STEP 7: Define model (LightGBM / RandomForest)"
      ],
      "metadata": {
        "id": "IQrMbmvHo_4J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "try:\n",
        "    from lightgbm import LGBMRegressor\n",
        "    USE_LGBM = True\n",
        "    print(\"üöÄ Using LightGBMRegressor (tuned + early stopping ready)\")\n",
        "\n",
        "    model = LGBMRegressor(\n",
        "      n_estimators=8000,       # ‡πÄ‡∏û‡∏¥‡πà‡∏° model capacity\n",
        "      learning_rate=0.015,     # ‡∏ä‡πâ‡∏≤‡∏•‡∏á‡∏≠‡∏µ‡∏Å‡∏ô‡∏¥‡∏î = smooth ‡∏Ç‡∏∂‡πâ‡∏ô\n",
        "      num_leaves=255,          # ‡∏¢‡∏∑‡∏î‡∏´‡∏¢‡∏∏‡πà‡∏ô‡∏Ç‡∏∂‡πâ‡∏ô\n",
        "      max_depth=-1,\n",
        "\n",
        "      min_child_samples=40,    # ‡∏Å‡∏±‡∏ô overfit ‡πÄ‡∏•‡πá‡∏Å‡∏ô‡πâ‡∏≠‡∏¢\n",
        "      subsample=0.9,           # ‡∏ó‡∏≥‡πÉ‡∏´‡πâ‡∏ï‡πâ‡∏ô‡πÑ‡∏°‡πâ randomized ‡∏ô‡πâ‡∏≠‡∏¢‡∏Å‡∏ß‡πà‡∏≤‡πÄ‡∏î‡∏¥‡∏°\n",
        "      colsample_bytree=0.7,    # ‡∏•‡∏î column sampling ‡πÉ‡∏´‡πâ‡∏ï‡πâ‡∏ô‡πÑ‡∏°‡πâ‡πÑ‡∏°‡πà‡∏ö‡πâ‡∏≤\n",
        "\n",
        "      reg_alpha=0.3,           # ‡∏ú‡πà‡∏≠‡∏ô regularization ‡πÉ‡∏´‡πâ‡πÇ‡∏°‡πÄ‡∏î‡∏•‡πÄ‡∏£‡∏µ‡∏¢‡∏ô‡∏£‡∏π‡πâ‡πÄ‡∏û‡∏¥‡πà‡∏°\n",
        "      reg_lambda=0.8,\n",
        "\n",
        "      random_state=42,\n",
        "      n_jobs=-1,\n",
        ")\n",
        "\n",
        "\n",
        "except ImportError:\n",
        "    from sklearn.ensemble import RandomForestRegressor\n",
        "    USE_LGBM = False\n",
        "    print(\"üöÄ LightGBM not found, using RandomForestRegressor instead (tuned)\")\n",
        "\n",
        "    model = RandomForestRegressor(\n",
        "        n_estimators=800,\n",
        "        max_depth=20,\n",
        "        min_samples_split=20,\n",
        "        min_samples_leaf=10,\n",
        "        max_features=\"sqrt\",\n",
        "        random_state=42,\n",
        "        n_jobs=-1,\n",
        "    )\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xONFuGxkxmxU",
        "outputId": "1d598c46-9cfa-4107-c88a-d8a341564eef"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üöÄ Using LightGBMRegressor (tuned + early stopping ready)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# STEP 8: Train model with early stopping + Evaluate on validation"
      ],
      "metadata": {
        "id": "IxwVNsGbpEY0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "USE_LOG_TARGET = False # ‡∏´‡∏£‡∏∑‡∏≠ True ‡∏Å‡πá‡πÑ‡∏î‡πâ‡∏ï‡∏≤‡∏°‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£\n",
        "\n",
        "if USE_LGBM and USE_LOG_TARGET:\n",
        "    print(\"üìê Training LGBM with log1p target + early stopping\")\n",
        "\n",
        "    y_train_log = np.log1p(y_train)\n",
        "    y_valid_log = np.log1p(y_valid)\n",
        "\n",
        "    model.fit(\n",
        "        X_train, y_train_log,\n",
        "        eval_set=[(X_valid, y_valid_log)],\n",
        "        eval_metric=\"mae\",\n",
        "        callbacks=[\n",
        "            early_stopping(stopping_rounds=200),\n",
        "            log_evaluation(100)\n",
        "        ]\n",
        "    )\n",
        "\n",
        "    y_valid_pred_log = model.predict(X_valid)\n",
        "    y_valid_pred = np.expm1(y_valid_pred_log)\n",
        "\n",
        "elif USE_LGBM and not USE_LOG_TARGET:\n",
        "    print(\"üìê Training LGBM with RAW target + early stopping\")\n",
        "\n",
        "    model.fit(\n",
        "        X_train, y_train,\n",
        "        eval_set=[(X_valid, y_valid)],\n",
        "        eval_metric=\"mae\",\n",
        "        callbacks=[\n",
        "            early_stopping(stopping_rounds=200),\n",
        "            log_evaluation(100)\n",
        "        ]\n",
        "    )\n",
        "\n",
        "    y_valid_pred = model.predict(X_valid)\n",
        "\n",
        "else:\n",
        "    # ‡∏Å‡∏£‡∏ì‡∏µ‡πÉ‡∏ä‡πâ RandomForest\n",
        "    print(\"üìê Training RandomForest\")\n",
        "    if USE_LOG_TARGET:\n",
        "        y_train_log = np.log1p(y_train)\n",
        "        model.fit(X_train, y_train_log)\n",
        "        y_valid_pred_log = model.predict(X_valid)\n",
        "        y_valid_pred = np.expm1(y_valid_pred_log)\n",
        "    else:\n",
        "        model.fit(X_train, y_train)\n",
        "        y_valid_pred = model.predict(X_valid)\n",
        "\n",
        "# clip ‡πÑ‡∏°‡πà‡πÉ‡∏´‡πâ negative\n",
        "y_valid_pred = np.maximum(y_valid_pred, 0)\n",
        "\n",
        "val_mae = mean_absolute_error(y_valid, y_valid_pred)\n",
        "val_nmae = nmae(y_valid, y_valid_pred)\n",
        "\n",
        "print(f\"Validation MAE : {val_mae:.4f}\")\n",
        "print(f\"Validation NMAE: {val_nmae:.6f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "STWIJEwFxotW",
        "outputId": "ae325b41-47c7-4bb3-a780-c777dedb59ff"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üìê Training LGBM with RAW target + early stopping\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.046399 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 5625\n",
            "[LightGBM] [Info] Number of data points in the train set: 83200, number of used features: 36\n",
            "[LightGBM] [Info] Start training from score 10408.760748\n",
            "Training until validation scores don't improve for 200 rounds\n",
            "[100]\tvalid_0's l1: 4928.94\tvalid_0's l2: 1.81876e+08\n",
            "[200]\tvalid_0's l1: 3163.01\tvalid_0's l2: 1.45463e+08\n",
            "[300]\tvalid_0's l1: 2987.39\tvalid_0's l2: 1.44032e+08\n",
            "[400]\tvalid_0's l1: 2991.23\tvalid_0's l2: 1.45028e+08\n",
            "Early stopping, best iteration is:\n",
            "[295]\tvalid_0's l1: 2988.83\tvalid_0's l2: 1.43969e+08\n",
            "Validation MAE : 2988.7675\n",
            "Validation NMAE: 0.292648\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# STEP 9: Retrain on full train data & predict test set"
      ],
      "metadata": {
        "id": "uF1w6vjfpIrk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"üìö Retraining on full data...\")\n",
        "\n",
        "if USE_LGBM and USE_LOG_TARGET:\n",
        "    y_full_log = np.log1p(y)\n",
        "    model.fit(X, y_full_log)\n",
        "    y_test_pred_log = model.predict(X_test)\n",
        "    y_test_pred = np.expm1(y_test_pred_log)\n",
        "\n",
        "elif USE_LGBM:\n",
        "    model.fit(X, y)\n",
        "    y_test_pred = model.predict(X_test)\n",
        "\n",
        "else:\n",
        "    # RandomForest\n",
        "    if USE_LOG_TARGET:\n",
        "        y_full_log = np.log1p(y)\n",
        "        model.fit(X, y_full_log)\n",
        "        y_test_pred_log = model.predict(X_test)\n",
        "        y_test_pred = np.expm1(y_test_pred_log)\n",
        "    else:\n",
        "        model.fit(X, y)\n",
        "        y_test_pred = model.predict(X_test)\n",
        "\n",
        "y_test_pred = np.maximum(y_test_pred, 0)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7Vx40dzkxruO",
        "outputId": "d171405c-c07c-426e-928c-74ede1fec954"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üìö Retraining on full data...\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.048805 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 5634\n",
            "[LightGBM] [Info] Number of data points in the train set: 104000, number of used features: 36\n",
            "[LightGBM] [Info] Start training from score 10369.578410\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# STEP 10: Build submission file"
      ],
      "metadata": {
        "id": "4hZXX053pLlT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "submission = pd.DataFrame({\n",
        "    \"id\": test[\"id\"],        # ‡∏ï‡πâ‡∏≠‡∏á‡∏°‡∏µ‡πÉ‡∏ô test.csv\n",
        "    \"task1\": 0,              # freeze / ‡πÉ‡∏´‡πâ‡πÄ‡∏õ‡πá‡∏ô default 0\n",
        "    \"task2\": 0,\n",
        "    \"task3\": y_test_pred,    # ‚ù§Ô∏è ‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡∏ó‡∏µ‡πà‡πÄ‡∏£‡∏≤‡∏ó‡∏≥‡∏ô‡∏≤‡∏¢\n",
        "    \"task4\": 0,\n",
        "    \"task5\": 0\n",
        "})\n",
        "\n",
        "submission.to_csv(OUTPUT_SUB_PATH, index=False)\n",
        "print(f\"‚úÖ Saved submission to: {OUTPUT_SUB_PATH}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GMifRHtbxuEu",
        "outputId": "a5e4293d-02cd-4ed0-8fce-aef6af9db398"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Saved submission to: submission_task3_baseline.csv\n"
          ]
        }
      ]
    }
  ]
}